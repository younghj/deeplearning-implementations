{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "# os.environ[\"THEANO_FLAGS\"] = \"mode=FAST_RUN,device=gpu,floatX=float32\"\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Dense, Input, Activation, Flatten, Add\n",
    "from keras.layers import BatchNormalization\n",
    "# from keras.layers import GlobalAveragePooling2D\n",
    "# from keras.optimizers import Adam, SGD\n",
    "# from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "\n",
    "from keras import backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 198s 1us/step\n",
      "170508288/170498071 [==============================] - 198s 1us/step\n"
     ]
    }
   ],
   "source": [
    "(xx_train, yy_train), (x_test, y_test) = cifar10.load_data()\n",
    "xx_train = xx_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "mean = np.mean(xx_train, axis=0)\n",
    "X_train -= mean\n",
    "X_test -= mean\n",
    "\n",
    "x_train = xx_train[:40000]\n",
    "y_train = yy_train[:40000]\n",
    "x_valid = xx_train[40000:50000]\n",
    "y_valid = yy_train[40000:50000]\n",
    "\n",
    "x_train = x_train/255.0\n",
    "x_valid = x_valid/255.0\n",
    "x_test = x_test/255.0\n",
    "\n",
    "# x_train = x_train/128.0\n",
    "# x_valid = x_valid/128.0\n",
    "# x_test = x_test/128.0\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_valid = np_utils.to_categorical(y_valid)\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(a,b):\n",
    "    shape1 = backend.int_shape(a)\n",
    "    shape2 = backend.int_shape(b)\n",
    "    w = int(round(shape1[1]/shape2[1]))\n",
    "    h = int(round(shape1[2]/shape2[2]))\n",
    "    eq = shape1[3] == shape2[3]\n",
    "    \n",
    "    tmp = a\n",
    "    print w,h,eq\n",
    "    print shape1, shape2\n",
    "    if w>1 or h>1 or not eq:\n",
    "        tmp = Conv2D(filters=shape2[3],kernel_size=(1,1),strides=(w,h),padding='valid',kernel_initializer='he_normal', kernel_regularizer=l2(0.0001))(a)\n",
    "    print backend.int_shape(tmp)\n",
    "    print\n",
    "    return Add()([tmp, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 True\n",
      "(None, 16, 16, 128) (None, 16, 16, 128)\n",
      "(None, 16, 16, 128)\n",
      "\n",
      "1 1 True\n",
      "(None, 16, 16, 128) (None, 16, 16, 128)\n",
      "(None, 16, 16, 128)\n",
      "\n",
      "1 1 True\n",
      "(None, 16, 16, 128) (None, 16, 16, 128)\n",
      "(None, 16, 16, 128)\n",
      "\n",
      "1 1 True\n",
      "(None, 16, 16, 128) (None, 16, 16, 128)\n",
      "(None, 16, 16, 128)\n",
      "\n",
      "1 1 True\n",
      "(None, 16, 16, 128) (None, 16, 16, 128)\n",
      "(None, 16, 16, 128)\n",
      "\n",
      "1 1 True\n",
      "(None, 16, 16, 128) (None, 16, 16, 128)\n",
      "(None, 16, 16, 128)\n",
      "\n",
      "1 1 True\n",
      "(None, 16, 16, 128) (None, 16, 16, 128)\n",
      "(None, 16, 16, 128)\n",
      "\n",
      "1 1 True\n",
      "(None, 16, 16, 128) (None, 16, 16, 128)\n",
      "(None, 16, 16, 128)\n",
      "\n",
      "1 1 True\n",
      "(None, 16, 16, 128) (None, 16, 16, 128)\n",
      "(None, 16, 16, 128)\n",
      "\n",
      "1 1 True\n",
      "(None, 16, 16, 128) (None, 16, 16, 128)\n",
      "(None, 16, 16, 128)\n",
      "\n",
      "1 1 True\n",
      "(None, 16, 16, 128) (None, 16, 16, 128)\n",
      "(None, 16, 16, 128)\n",
      "\n",
      "1 1 True\n",
      "(None, 16, 16, 128) (None, 16, 16, 128)\n",
      "(None, 16, 16, 128)\n",
      "\n",
      "1 1 True\n",
      "(None, 16, 16, 128) (None, 16, 16, 128)\n",
      "(None, 16, 16, 128)\n",
      "\n",
      "1 1 True\n",
      "(None, 16, 16, 128) (None, 16, 16, 128)\n",
      "(None, 16, 16, 128)\n",
      "\n",
      "1 1 True\n",
      "(None, 16, 16, 128) (None, 16, 16, 128)\n",
      "(None, 16, 16, 128)\n",
      "\n",
      "1 1 True\n",
      "(None, 16, 16, 128) (None, 16, 16, 128)\n",
      "(None, 16, 16, 128)\n",
      "\n",
      "1 1 True\n",
      "(None, 16, 16, 128) (None, 16, 16, 128)\n",
      "(None, 16, 16, 128)\n",
      "\n",
      "1 1 True\n",
      "(None, 16, 16, 128) (None, 16, 16, 128)\n",
      "(None, 16, 16, 128)\n",
      "\n",
      "1 1 True\n",
      "(None, 16, 16, 128) (None, 16, 16, 128)\n",
      "(None, 16, 16, 128)\n",
      "\n",
      "1 1 True\n",
      "(None, 16, 16, 128) (None, 16, 16, 128)\n",
      "(None, 16, 16, 128)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def layer(num_filt, size, strides, inp):\n",
    "    tmp = BatchNormalization(axis=3)(inp)\n",
    "    tmp = Activation('relu')(tmp)\n",
    "    tmp = Conv2D(num_filt, size, strides=strides, padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0001))(tmp)\n",
    "    return tmp\n",
    "\n",
    "l = Input(x_train.shape[1:])\n",
    "\n",
    "x = Conv2D(128, (7,7), strides=2, padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0001))(l)\n",
    "x = BatchNormalization(axis=3)(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "#first layer\n",
    "num = 32\n",
    "xtmp = Conv2D(num, (1,1), strides=1, \n",
    "              padding='same', \n",
    "              kernel_initializer='he_normal', \n",
    "              kernel_regularizer=l2(0.0001))(x)\n",
    "xtmp = layer(num, (3,3), 1, xtmp)\n",
    "xtmp = layer(num*4, (1,1), 1, xtmp)\n",
    "\n",
    "x = add(x,xtmp)\n",
    "\n",
    "#other layer\n",
    "xtmp = layer(num, (1,1), 1, x)\n",
    "xtmp = layer(num, (3,3), 1, xtmp)\n",
    "xtmp = layer(num*4, (1,1), 1, xtmp)\n",
    "x = add(x,xtmp)\n",
    "\n",
    "for i in xrange(9):\n",
    "    xtmp = layer(num, (1,1), 1, x)\n",
    "    xtmp = layer(num, (3,3), 1, xtmp)\n",
    "    xtmp = layer(num*4, (1,1), 1, xtmp)\n",
    "    x = add(x,xtmp)\n",
    "\n",
    "    #other layer\n",
    "    xtmp = layer(num, (1,1), 1, x)\n",
    "    xtmp = layer(num, (3,3), 1, xtmp)\n",
    "    xtmp = layer(num*4, (1,1), 1, xtmp)\n",
    "    x = add(x,xtmp)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "xshape = backend.int_shape(x)\n",
    "x = AveragePooling2D(pool_size=(xshape[1],xshape[2]), strides=(1,1))(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(10, activation='softmax', kernel_initializer='he_normal', kernel_regularizer=l2(0.0001))(x)\n",
    "\n",
    "early=EarlyStopping(monitor='val_acc', patience=15, verbose=1, mode='auto')\n",
    "filepath=\"weights.best.hdf5\"\n",
    "checkpoint=ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 False\n",
      "(None, 16, 16, 64) (None, 16, 16, 256)\n",
      "(None, 16, 16, 256)\n",
      "\n",
      "1 1 True\n",
      "(None, 16, 16, 256) (None, 16, 16, 256)\n",
      "(None, 16, 16, 256)\n",
      "\n",
      "2 2 False\n",
      "(None, 16, 16, 256) (None, 8, 8, 512)\n",
      "(None, 8, 8, 512)\n",
      "\n",
      "1 1 True\n",
      "(None, 8, 8, 512) (None, 8, 8, 512)\n",
      "(None, 8, 8, 512)\n",
      "\n",
      "2 2 False\n",
      "(None, 8, 8, 512) (None, 4, 4, 1024)\n",
      "(None, 4, 4, 1024)\n",
      "\n",
      "1 1 True\n",
      "(None, 4, 4, 1024) (None, 4, 4, 1024)\n",
      "(None, 4, 4, 1024)\n",
      "\n",
      "2 2 False\n",
      "(None, 4, 4, 1024) (None, 2, 2, 2048)\n",
      "(None, 2, 2, 2048)\n",
      "\n",
      "1 1 True\n",
      "(None, 2, 2, 2048) (None, 2, 2, 2048)\n",
      "(None, 2, 2, 2048)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def layer(num_filt, size, strides, inp):\n",
    "    tmp = BatchNormalization(axis=3)(inp)\n",
    "    tmp = Activation('relu')(tmp)\n",
    "    tmp = Conv2D(num_filt, size, strides=strides, padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0001))(tmp)\n",
    "    return tmp\n",
    "\n",
    "l = Input(x_train.shape[1:])\n",
    "\n",
    "x = Conv2D(64, (7,7), strides=2, padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0001))(l)\n",
    "x = BatchNormalization(axis=3)(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "#first layer\n",
    "num = 64\n",
    "xtmp = Conv2D(num, (1,1), strides=1, \n",
    "              padding='same', \n",
    "              kernel_initializer='he_normal', \n",
    "              kernel_regularizer=l2(0.0001))(x)\n",
    "xtmp = layer(num, (3,3), 1, xtmp)\n",
    "xtmp = layer(num*4, (1,1), 1, xtmp)\n",
    "\n",
    "x = add(x,xtmp)\n",
    "\n",
    "#other layer\n",
    "xtmp = layer(num, (1,1), 1, x)\n",
    "xtmp = layer(num, (3,3), 1, xtmp)\n",
    "xtmp = layer(num*4, (1,1), 1, xtmp)\n",
    "x = add(x,xtmp)\n",
    "\n",
    "for i in xrange(3):\n",
    "    num *= 2\n",
    "    xtmp = layer(num, (1,1), 2, x)\n",
    "    xtmp = layer(num, (3,3), 1, xtmp)\n",
    "    xtmp = layer(num*4, (1,1), 1, xtmp)\n",
    "    x = add(x,xtmp)\n",
    "\n",
    "    #other layer\n",
    "    xtmp = layer(num, (1,1), 1, x)\n",
    "    xtmp = layer(num, (3,3), 1, xtmp)\n",
    "    xtmp = layer(num*4, (1,1), 1, xtmp)\n",
    "    x = add(x,xtmp)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "xshape = backend.int_shape(x)\n",
    "x = AveragePooling2D(pool_size=(xshape[1],xshape[2]), strides=(1,1))(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(10, activation='softmax', kernel_initializer='he_normal', kernel_regularizer=l2(0.0001))(x)\n",
    "\n",
    "early=EarlyStopping(monitor='val_acc', patience=15, verbose=1, mode='auto')\n",
    "filepath=\"weights.best.hdf5\"\n",
    "checkpoint=ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 True\n",
      "(None, 16, 16, 64) (None, 16, 16, 64)\n",
      "(None, 16, 16, 64)\n",
      "\n",
      "1 1 True\n",
      "(None, 16, 16, 64) (None, 16, 16, 64)\n",
      "(None, 16, 16, 64)\n",
      "\n",
      "2 2 False\n",
      "(None, 16, 16, 64) (None, 8, 8, 128)\n",
      "(None, 8, 8, 128)\n",
      "\n",
      "1 1 True\n",
      "(None, 8, 8, 128) (None, 8, 8, 128)\n",
      "(None, 8, 8, 128)\n",
      "\n",
      "2 2 False\n",
      "(None, 8, 8, 128) (None, 4, 4, 256)\n",
      "(None, 4, 4, 256)\n",
      "\n",
      "1 1 True\n",
      "(None, 4, 4, 256) (None, 4, 4, 256)\n",
      "(None, 4, 4, 256)\n",
      "\n",
      "2 2 False\n",
      "(None, 4, 4, 256) (None, 2, 2, 512)\n",
      "(None, 2, 2, 512)\n",
      "\n",
      "1 1 True\n",
      "(None, 2, 2, 512) (None, 2, 2, 512)\n",
      "(None, 2, 2, 512)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def layer(num_filt, strides, inp):\n",
    "    tmp = BatchNormalization(axis=3)(inp)\n",
    "    tmp = Activation('relu')(tmp)\n",
    "    tmp = Conv2D(num_filt, (3,3), strides=strides, padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0001))(tmp)\n",
    "    return tmp\n",
    "\n",
    "l = Input(x_train.shape[1:])\n",
    "\n",
    "x = Conv2D(64, (7,7), strides=2, padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0001))(l)\n",
    "x = BatchNormalization(axis=3)(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "#first layer\n",
    "num = 64\n",
    "xtmp = Conv2D(num, (3,3), strides=1, \n",
    "              padding='same', \n",
    "              kernel_initializer='he_normal', \n",
    "              kernel_regularizer=l2(0.0001))(x)\n",
    "xtmp = layer(num, 1, xtmp)\n",
    "x = add(x,xtmp)\n",
    "\n",
    "#other layer\n",
    "xtmp = layer(num, 1, x)\n",
    "xtmp = layer(num, 1, xtmp)\n",
    "x = add(x,xtmp)\n",
    "\n",
    "for i in xrange(3):\n",
    "    num *= 2\n",
    "    xtmp = layer(num, 2, x)\n",
    "    xtmp = layer(num, 1, xtmp)\n",
    "    x = add(x,xtmp)\n",
    "    \n",
    "    #other layer\n",
    "    xtmp = layer(num, 1, x)\n",
    "    xtmp = layer(num, 1, xtmp)\n",
    "    x = add(x,xtmp)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "xshape = backend.int_shape(x)\n",
    "x = AveragePooling2D(pool_size=(xshape[1],xshape[2]), strides=(1,1))(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(10, activation='softmax', kernel_initializer='he_normal', kernel_regularizer=l2(0.0001))(x)\n",
    "\n",
    "early=EarlyStopping(monitor='val_acc', patience=15, verbose=1, mode='auto')\n",
    "filepath=\"weights.best.hdf5\"\n",
    "checkpoint=ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_23 (InputLayer)           (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_498 (Conv2D)             (None, 16, 16, 128)  18944       input_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_432 (BatchN (None, 16, 16, 128)  512         conv2d_498[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_432 (Activation)     (None, 16, 16, 128)  0           batch_normalization_432[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_499 (Conv2D)             (None, 16, 16, 32)   4128        activation_432[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_433 (BatchN (None, 16, 16, 32)   128         conv2d_499[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_433 (Activation)     (None, 16, 16, 32)   0           batch_normalization_433[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_500 (Conv2D)             (None, 16, 16, 32)   9248        activation_433[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_434 (BatchN (None, 16, 16, 32)   128         conv2d_500[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_434 (Activation)     (None, 16, 16, 32)   0           batch_normalization_434[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_501 (Conv2D)             (None, 16, 16, 128)  4224        activation_434[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_153 (Add)                   (None, 16, 16, 128)  0           activation_432[0][0]             \n",
      "                                                                 conv2d_501[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_435 (BatchN (None, 16, 16, 128)  512         add_153[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_435 (Activation)     (None, 16, 16, 128)  0           batch_normalization_435[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_502 (Conv2D)             (None, 16, 16, 32)   4128        activation_435[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_436 (BatchN (None, 16, 16, 32)   128         conv2d_502[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_436 (Activation)     (None, 16, 16, 32)   0           batch_normalization_436[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_503 (Conv2D)             (None, 16, 16, 32)   9248        activation_436[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_437 (BatchN (None, 16, 16, 32)   128         conv2d_503[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_437 (Activation)     (None, 16, 16, 32)   0           batch_normalization_437[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_504 (Conv2D)             (None, 16, 16, 128)  4224        activation_437[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_154 (Add)                   (None, 16, 16, 128)  0           add_153[0][0]                    \n",
      "                                                                 conv2d_504[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_438 (BatchN (None, 16, 16, 128)  512         add_154[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_438 (Activation)     (None, 16, 16, 128)  0           batch_normalization_438[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_505 (Conv2D)             (None, 16, 16, 32)   4128        activation_438[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_439 (BatchN (None, 16, 16, 32)   128         conv2d_505[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_439 (Activation)     (None, 16, 16, 32)   0           batch_normalization_439[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_506 (Conv2D)             (None, 16, 16, 32)   9248        activation_439[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_440 (BatchN (None, 16, 16, 32)   128         conv2d_506[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_440 (Activation)     (None, 16, 16, 32)   0           batch_normalization_440[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_507 (Conv2D)             (None, 16, 16, 128)  4224        activation_440[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_155 (Add)                   (None, 16, 16, 128)  0           add_154[0][0]                    \n",
      "                                                                 conv2d_507[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_441 (BatchN (None, 16, 16, 128)  512         add_155[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_441 (Activation)     (None, 16, 16, 128)  0           batch_normalization_441[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_508 (Conv2D)             (None, 16, 16, 32)   4128        activation_441[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_442 (BatchN (None, 16, 16, 32)   128         conv2d_508[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_442 (Activation)     (None, 16, 16, 32)   0           batch_normalization_442[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_509 (Conv2D)             (None, 16, 16, 32)   9248        activation_442[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_443 (BatchN (None, 16, 16, 32)   128         conv2d_509[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_443 (Activation)     (None, 16, 16, 32)   0           batch_normalization_443[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_510 (Conv2D)             (None, 16, 16, 128)  4224        activation_443[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_156 (Add)                   (None, 16, 16, 128)  0           add_155[0][0]                    \n",
      "                                                                 conv2d_510[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_444 (BatchN (None, 16, 16, 128)  512         add_156[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_444 (Activation)     (None, 16, 16, 128)  0           batch_normalization_444[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_511 (Conv2D)             (None, 16, 16, 32)   4128        activation_444[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_445 (BatchN (None, 16, 16, 32)   128         conv2d_511[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_445 (Activation)     (None, 16, 16, 32)   0           batch_normalization_445[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_512 (Conv2D)             (None, 16, 16, 32)   9248        activation_445[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_446 (BatchN (None, 16, 16, 32)   128         conv2d_512[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_446 (Activation)     (None, 16, 16, 32)   0           batch_normalization_446[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_513 (Conv2D)             (None, 16, 16, 128)  4224        activation_446[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_157 (Add)                   (None, 16, 16, 128)  0           add_156[0][0]                    \n",
      "                                                                 conv2d_513[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_447 (BatchN (None, 16, 16, 128)  512         add_157[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_447 (Activation)     (None, 16, 16, 128)  0           batch_normalization_447[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_514 (Conv2D)             (None, 16, 16, 32)   4128        activation_447[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_448 (BatchN (None, 16, 16, 32)   128         conv2d_514[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_448 (Activation)     (None, 16, 16, 32)   0           batch_normalization_448[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_515 (Conv2D)             (None, 16, 16, 32)   9248        activation_448[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_449 (BatchN (None, 16, 16, 32)   128         conv2d_515[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_449 (Activation)     (None, 16, 16, 32)   0           batch_normalization_449[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_516 (Conv2D)             (None, 16, 16, 128)  4224        activation_449[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_158 (Add)                   (None, 16, 16, 128)  0           add_157[0][0]                    \n",
      "                                                                 conv2d_516[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_450 (BatchN (None, 16, 16, 128)  512         add_158[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_450 (Activation)     (None, 16, 16, 128)  0           batch_normalization_450[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_517 (Conv2D)             (None, 16, 16, 32)   4128        activation_450[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_451 (BatchN (None, 16, 16, 32)   128         conv2d_517[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_451 (Activation)     (None, 16, 16, 32)   0           batch_normalization_451[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_518 (Conv2D)             (None, 16, 16, 32)   9248        activation_451[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_452 (BatchN (None, 16, 16, 32)   128         conv2d_518[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_452 (Activation)     (None, 16, 16, 32)   0           batch_normalization_452[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_519 (Conv2D)             (None, 16, 16, 128)  4224        activation_452[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_159 (Add)                   (None, 16, 16, 128)  0           add_158[0][0]                    \n",
      "                                                                 conv2d_519[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_453 (BatchN (None, 16, 16, 128)  512         add_159[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_453 (Activation)     (None, 16, 16, 128)  0           batch_normalization_453[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_520 (Conv2D)             (None, 16, 16, 32)   4128        activation_453[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_454 (BatchN (None, 16, 16, 32)   128         conv2d_520[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_454 (Activation)     (None, 16, 16, 32)   0           batch_normalization_454[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_521 (Conv2D)             (None, 16, 16, 32)   9248        activation_454[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_455 (BatchN (None, 16, 16, 32)   128         conv2d_521[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_455 (Activation)     (None, 16, 16, 32)   0           batch_normalization_455[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_522 (Conv2D)             (None, 16, 16, 128)  4224        activation_455[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_160 (Add)                   (None, 16, 16, 128)  0           add_159[0][0]                    \n",
      "                                                                 conv2d_522[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_456 (BatchN (None, 16, 16, 128)  512         add_160[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_456 (Activation)     (None, 16, 16, 128)  0           batch_normalization_456[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_523 (Conv2D)             (None, 16, 16, 32)   4128        activation_456[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_457 (BatchN (None, 16, 16, 32)   128         conv2d_523[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_457 (Activation)     (None, 16, 16, 32)   0           batch_normalization_457[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_524 (Conv2D)             (None, 16, 16, 32)   9248        activation_457[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_458 (BatchN (None, 16, 16, 32)   128         conv2d_524[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_458 (Activation)     (None, 16, 16, 32)   0           batch_normalization_458[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_525 (Conv2D)             (None, 16, 16, 128)  4224        activation_458[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_161 (Add)                   (None, 16, 16, 128)  0           add_160[0][0]                    \n",
      "                                                                 conv2d_525[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_459 (BatchN (None, 16, 16, 128)  512         add_161[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_459 (Activation)     (None, 16, 16, 128)  0           batch_normalization_459[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_526 (Conv2D)             (None, 16, 16, 32)   4128        activation_459[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_460 (BatchN (None, 16, 16, 32)   128         conv2d_526[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_460 (Activation)     (None, 16, 16, 32)   0           batch_normalization_460[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_527 (Conv2D)             (None, 16, 16, 32)   9248        activation_460[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_461 (BatchN (None, 16, 16, 32)   128         conv2d_527[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_461 (Activation)     (None, 16, 16, 32)   0           batch_normalization_461[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_528 (Conv2D)             (None, 16, 16, 128)  4224        activation_461[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_162 (Add)                   (None, 16, 16, 128)  0           add_161[0][0]                    \n",
      "                                                                 conv2d_528[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_462 (BatchN (None, 16, 16, 128)  512         add_162[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_462 (Activation)     (None, 16, 16, 128)  0           batch_normalization_462[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_529 (Conv2D)             (None, 16, 16, 32)   4128        activation_462[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_463 (BatchN (None, 16, 16, 32)   128         conv2d_529[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_463 (Activation)     (None, 16, 16, 32)   0           batch_normalization_463[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_530 (Conv2D)             (None, 16, 16, 32)   9248        activation_463[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_464 (BatchN (None, 16, 16, 32)   128         conv2d_530[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_464 (Activation)     (None, 16, 16, 32)   0           batch_normalization_464[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_531 (Conv2D)             (None, 16, 16, 128)  4224        activation_464[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_163 (Add)                   (None, 16, 16, 128)  0           add_162[0][0]                    \n",
      "                                                                 conv2d_531[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_465 (BatchN (None, 16, 16, 128)  512         add_163[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_465 (Activation)     (None, 16, 16, 128)  0           batch_normalization_465[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_532 (Conv2D)             (None, 16, 16, 32)   4128        activation_465[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_466 (BatchN (None, 16, 16, 32)   128         conv2d_532[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_466 (Activation)     (None, 16, 16, 32)   0           batch_normalization_466[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_533 (Conv2D)             (None, 16, 16, 32)   9248        activation_466[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_467 (BatchN (None, 16, 16, 32)   128         conv2d_533[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_467 (Activation)     (None, 16, 16, 32)   0           batch_normalization_467[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_534 (Conv2D)             (None, 16, 16, 128)  4224        activation_467[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_164 (Add)                   (None, 16, 16, 128)  0           add_163[0][0]                    \n",
      "                                                                 conv2d_534[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_468 (BatchN (None, 16, 16, 128)  512         add_164[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_468 (Activation)     (None, 16, 16, 128)  0           batch_normalization_468[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_535 (Conv2D)             (None, 16, 16, 32)   4128        activation_468[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_469 (BatchN (None, 16, 16, 32)   128         conv2d_535[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_469 (Activation)     (None, 16, 16, 32)   0           batch_normalization_469[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_536 (Conv2D)             (None, 16, 16, 32)   9248        activation_469[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_470 (BatchN (None, 16, 16, 32)   128         conv2d_536[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_470 (Activation)     (None, 16, 16, 32)   0           batch_normalization_470[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_537 (Conv2D)             (None, 16, 16, 128)  4224        activation_470[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_165 (Add)                   (None, 16, 16, 128)  0           add_164[0][0]                    \n",
      "                                                                 conv2d_537[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_471 (BatchN (None, 16, 16, 128)  512         add_165[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_471 (Activation)     (None, 16, 16, 128)  0           batch_normalization_471[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_538 (Conv2D)             (None, 16, 16, 32)   4128        activation_471[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_472 (BatchN (None, 16, 16, 32)   128         conv2d_538[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_472 (Activation)     (None, 16, 16, 32)   0           batch_normalization_472[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_539 (Conv2D)             (None, 16, 16, 32)   9248        activation_472[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_473 (BatchN (None, 16, 16, 32)   128         conv2d_539[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_473 (Activation)     (None, 16, 16, 32)   0           batch_normalization_473[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_540 (Conv2D)             (None, 16, 16, 128)  4224        activation_473[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_166 (Add)                   (None, 16, 16, 128)  0           add_165[0][0]                    \n",
      "                                                                 conv2d_540[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_474 (BatchN (None, 16, 16, 128)  512         add_166[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_474 (Activation)     (None, 16, 16, 128)  0           batch_normalization_474[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_541 (Conv2D)             (None, 16, 16, 32)   4128        activation_474[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_475 (BatchN (None, 16, 16, 32)   128         conv2d_541[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_475 (Activation)     (None, 16, 16, 32)   0           batch_normalization_475[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_542 (Conv2D)             (None, 16, 16, 32)   9248        activation_475[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_476 (BatchN (None, 16, 16, 32)   128         conv2d_542[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_476 (Activation)     (None, 16, 16, 32)   0           batch_normalization_476[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_543 (Conv2D)             (None, 16, 16, 128)  4224        activation_476[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_167 (Add)                   (None, 16, 16, 128)  0           add_166[0][0]                    \n",
      "                                                                 conv2d_543[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_477 (BatchN (None, 16, 16, 128)  512         add_167[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_477 (Activation)     (None, 16, 16, 128)  0           batch_normalization_477[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_544 (Conv2D)             (None, 16, 16, 32)   4128        activation_477[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_478 (BatchN (None, 16, 16, 32)   128         conv2d_544[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_478 (Activation)     (None, 16, 16, 32)   0           batch_normalization_478[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_545 (Conv2D)             (None, 16, 16, 32)   9248        activation_478[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_479 (BatchN (None, 16, 16, 32)   128         conv2d_545[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_479 (Activation)     (None, 16, 16, 32)   0           batch_normalization_479[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_546 (Conv2D)             (None, 16, 16, 128)  4224        activation_479[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_168 (Add)                   (None, 16, 16, 128)  0           add_167[0][0]                    \n",
      "                                                                 conv2d_546[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_480 (BatchN (None, 16, 16, 128)  512         add_168[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_480 (Activation)     (None, 16, 16, 128)  0           batch_normalization_480[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_547 (Conv2D)             (None, 16, 16, 32)   4128        activation_480[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_481 (BatchN (None, 16, 16, 32)   128         conv2d_547[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_481 (Activation)     (None, 16, 16, 32)   0           batch_normalization_481[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_548 (Conv2D)             (None, 16, 16, 32)   9248        activation_481[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_482 (BatchN (None, 16, 16, 32)   128         conv2d_548[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_482 (Activation)     (None, 16, 16, 32)   0           batch_normalization_482[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_549 (Conv2D)             (None, 16, 16, 128)  4224        activation_482[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_169 (Add)                   (None, 16, 16, 128)  0           add_168[0][0]                    \n",
      "                                                                 conv2d_549[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_483 (BatchN (None, 16, 16, 128)  512         add_169[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_483 (Activation)     (None, 16, 16, 128)  0           batch_normalization_483[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_550 (Conv2D)             (None, 16, 16, 32)   4128        activation_483[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_484 (BatchN (None, 16, 16, 32)   128         conv2d_550[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_484 (Activation)     (None, 16, 16, 32)   0           batch_normalization_484[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_551 (Conv2D)             (None, 16, 16, 32)   9248        activation_484[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_485 (BatchN (None, 16, 16, 32)   128         conv2d_551[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_485 (Activation)     (None, 16, 16, 32)   0           batch_normalization_485[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_552 (Conv2D)             (None, 16, 16, 128)  4224        activation_485[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_170 (Add)                   (None, 16, 16, 128)  0           add_169[0][0]                    \n",
      "                                                                 conv2d_552[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_486 (BatchN (None, 16, 16, 128)  512         add_170[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_486 (Activation)     (None, 16, 16, 128)  0           batch_normalization_486[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_553 (Conv2D)             (None, 16, 16, 32)   4128        activation_486[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_487 (BatchN (None, 16, 16, 32)   128         conv2d_553[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_487 (Activation)     (None, 16, 16, 32)   0           batch_normalization_487[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_554 (Conv2D)             (None, 16, 16, 32)   9248        activation_487[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_488 (BatchN (None, 16, 16, 32)   128         conv2d_554[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_488 (Activation)     (None, 16, 16, 32)   0           batch_normalization_488[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_555 (Conv2D)             (None, 16, 16, 128)  4224        activation_488[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_171 (Add)                   (None, 16, 16, 128)  0           add_170[0][0]                    \n",
      "                                                                 conv2d_555[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_489 (BatchN (None, 16, 16, 128)  512         add_171[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_489 (Activation)     (None, 16, 16, 128)  0           batch_normalization_489[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_556 (Conv2D)             (None, 16, 16, 32)   4128        activation_489[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_490 (BatchN (None, 16, 16, 32)   128         conv2d_556[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_490 (Activation)     (None, 16, 16, 32)   0           batch_normalization_490[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_557 (Conv2D)             (None, 16, 16, 32)   9248        activation_490[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_491 (BatchN (None, 16, 16, 32)   128         conv2d_557[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_491 (Activation)     (None, 16, 16, 32)   0           batch_normalization_491[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_558 (Conv2D)             (None, 16, 16, 128)  4224        activation_491[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_172 (Add)                   (None, 16, 16, 128)  0           add_171[0][0]                    \n",
      "                                                                 conv2d_558[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_492 (BatchN (None, 16, 16, 128)  512         add_172[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_492 (Activation)     (None, 16, 16, 128)  0           batch_normalization_492[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_17 (AveragePo (None, 1, 1, 128)    0           activation_492[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_17 (Flatten)            (None, 128)          0           average_pooling2d_17[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 10)           1290        flatten_17[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 388,106\n",
      "Trainable params: 380,170\n",
      "Non-trainable params: 7,936\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(l,x)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "      loss='categorical_crossentropy',\n",
    "      metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#if training was cut short\n",
    "model = load_model('weights.best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "39968/40000 [============================>.] - ETA: 1s - loss: 1.8513 - acc: 0.4921Epoch 00001: val_acc improved from -inf to 0.51920, saving model to weights.best.hdf5\n",
      "40000/40000 [==============================] - 1529s 38ms/step - loss: 1.8510 - acc: 0.4923 - val_loss: 1.6813 - val_acc: 0.5192\n",
      "Epoch 2/200\n",
      "39968/40000 [============================>.] - ETA: 1s - loss: 1.4431 - acc: 0.6005Epoch 00002: val_acc improved from 0.51920 to 0.54210, saving model to weights.best.hdf5\n",
      "40000/40000 [==============================] - 1501s 38ms/step - loss: 1.4428 - acc: 0.6007 - val_loss: 1.5998 - val_acc: 0.5421\n",
      "Epoch 3/200\n",
      "39968/40000 [============================>.] - ETA: 1s - loss: 1.2512 - acc: 0.6554Epoch 00003: val_acc did not improve\n",
      "40000/40000 [==============================] - 1482s 37ms/step - loss: 1.2512 - acc: 0.6553 - val_loss: 1.7411 - val_acc: 0.5039\n",
      "Epoch 4/200\n",
      "39968/40000 [============================>.] - ETA: 1s - loss: 1.1263 - acc: 0.6958Epoch 00004: val_acc improved from 0.54210 to 0.57070, saving model to weights.best.hdf5\n",
      "40000/40000 [==============================] - 1377s 34ms/step - loss: 1.1263 - acc: 0.6958 - val_loss: 1.4911 - val_acc: 0.5707\n",
      "Epoch 5/200\n",
      "39968/40000 [============================>.] - ETA: 1s - loss: 1.0241 - acc: 0.7291Epoch 00005: val_acc did not improve\n",
      "40000/40000 [==============================] - 1377s 34ms/step - loss: 1.0239 - acc: 0.7291 - val_loss: 1.6956 - val_acc: 0.5394\n",
      "Epoch 6/200\n",
      "39968/40000 [============================>.] - ETA: 1s - loss: 0.9538 - acc: 0.7516Epoch 00006: val_acc improved from 0.57070 to 0.70940, saving model to weights.best.hdf5\n",
      "40000/40000 [==============================] - 1372s 34ms/step - loss: 0.9538 - acc: 0.7515 - val_loss: 1.0765 - val_acc: 0.7094\n",
      "Epoch 7/200\n",
      "39968/40000 [============================>.] - ETA: 1s - loss: 0.8991 - acc: 0.7687Epoch 00007: val_acc did not improve\n",
      "40000/40000 [==============================] - 1378s 34ms/step - loss: 0.8991 - acc: 0.7688 - val_loss: 1.2530 - val_acc: 0.6619\n",
      "Epoch 8/200\n",
      "39968/40000 [============================>.] - ETA: 1s - loss: 0.8604 - acc: 0.7826Epoch 00008: val_acc did not improve\n",
      "40000/40000 [==============================] - 1372s 34ms/step - loss: 0.8602 - acc: 0.7826 - val_loss: 1.1768 - val_acc: 0.6772\n",
      "Epoch 9/200\n",
      "39968/40000 [============================>.] - ETA: 1s - loss: 0.8195 - acc: 0.7978Epoch 00009: val_acc did not improve\n",
      "40000/40000 [==============================] - 1361s 34ms/step - loss: 0.8196 - acc: 0.7977 - val_loss: 1.2887 - val_acc: 0.6391\n",
      "Epoch 10/200\n",
      "39968/40000 [============================>.] - ETA: 1s - loss: 0.7900 - acc: 0.8074Epoch 00010: val_acc did not improve\n",
      "40000/40000 [==============================] - 1373s 34ms/step - loss: 0.7900 - acc: 0.8075 - val_loss: 1.1226 - val_acc: 0.7008\n",
      "Epoch 11/200\n",
      "39968/40000 [============================>.] - ETA: 1s - loss: 0.7584 - acc: 0.8191Epoch 00011: val_acc did not improve\n",
      "40000/40000 [==============================] - 1366s 34ms/step - loss: 0.7583 - acc: 0.8192 - val_loss: 1.7373 - val_acc: 0.5543\n",
      "Epoch 12/200\n",
      "39968/40000 [============================>.] - ETA: 1s - loss: 0.7366 - acc: 0.8275Epoch 00012: val_acc did not improve\n",
      "40000/40000 [==============================] - 1499s 37ms/step - loss: 0.7366 - acc: 0.8275 - val_loss: 1.4965 - val_acc: 0.6044\n",
      "Epoch 13/200\n",
      " 6944/40000 [====>.........................] - ETA: 19:02 - loss: 0.6553 - acc: 0.8599"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,y_train,\n",
    "          batch_size=32, epochs=200,\n",
    "          shuffle=True,\n",
    "          validation_data=(x_valid, y_valid), \n",
    "          callbacks=[checkpoint, early])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 25s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "res = model.evaluate(x_test, y_test, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.71 Accuracy: 67.62%\n"
     ]
    }
   ],
   "source": [
    "print('Loss: %.2f Accuracy: %.2f%%' % (res[0], res[1]*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
