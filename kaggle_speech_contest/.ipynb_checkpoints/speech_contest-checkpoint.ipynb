{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import isdir, join\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Math\n",
    "import numpy as np\n",
    "from scipy.fftpack import fft\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import scipy\n",
    "import librosa\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import IPython.display as ipd\n",
    "import librosa.display\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "import pandas as pd\n",
    "from tensorflow.contrib import signal\n",
    "\n",
    "import python_speech_features\n",
    "\n",
    "# Data Loading\n",
    "import re\n",
    "from glob import glob\n",
    "\n",
    "# Prediction\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Layers\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import layers\n",
    "from tensorflow.contrib.framework import arg_scope\n",
    "from tflearn.layers.conv import global_avg_pool\n",
    "from tensorflow.contrib.layers import batch_norm, flatten\n",
    "\n",
    "# it's a magic function :)\n",
    "# Training\n",
    "from tensorflow.contrib.learn.python.learn.learn_io.generator_io import generator_input_fn\n",
    "\n",
    "import cv2\n",
    "\n",
    "\n",
    "#KERAS\n",
    "\n",
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "# os.environ[\"THEANO_FLAGS\"] = \"mode=FAST_RUN,device=gpu,floatX=float32\"\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Dense, Input, Activation, Flatten, Add\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras import backend\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 57929 train, 6798 val, and 6 bg noise samples\n"
     ]
    }
   ],
   "source": [
    "DATADIR = './data' # unzipped train and test data\n",
    "OUTDIR = './model-k' # just a random name\n",
    "\n",
    "POSSIBLE_LABELS = 'yes no up down left right on off stop go silence unknown'.split()\n",
    "id2name = {i: name for i, name in enumerate(POSSIBLE_LABELS)}\n",
    "name2id = {name: i for i, name in id2name.items()}\n",
    "\n",
    "\n",
    "def load_data(data_dir):\n",
    "    \"\"\" Return 2 lists of tuples:\n",
    "    [(class_id, user_id, path), ...] for train\n",
    "    [(class_id, user_id, path), ...] for validation\n",
    "    \"\"\"\n",
    "    # Just a simple regexp for paths with three groups:\n",
    "    # prefix, label, user_id\n",
    "    pattern = re.compile(\"(.+\\/)?(\\w+)\\/([^_]+)_.+wav\")\n",
    "    all_files = glob(os.path.join(data_dir, 'train/audio/*/*wav'))\n",
    "\n",
    "    with open(os.path.join(data_dir, 'train/validation_list.txt'), 'r') as fin:\n",
    "        validation_files = fin.readlines()\n",
    "    valset = set()\n",
    "    for entry in validation_files:\n",
    "        r = re.match(pattern, entry)\n",
    "        if r:\n",
    "            valset.add(r.group(3))\n",
    "\n",
    "    possible = set(POSSIBLE_LABELS)\n",
    "    train, val, bg_noise = [], [], []\n",
    "    for entry in all_files:\n",
    "        r = re.match(pattern, entry)\n",
    "        if r:\n",
    "            label, uid = r.group(2), r.group(3)\n",
    "            if label == '_background_noise_':\n",
    "                bg_noise.append(entry)\n",
    "                label = 'silence'\n",
    "            if label not in possible:\n",
    "                label = 'unknown'\n",
    "\n",
    "            label_id = name2id[label]\n",
    "\n",
    "            sample = (label_id, uid, entry)\n",
    "            if uid in valset:\n",
    "                val.append(sample)\n",
    "            else:\n",
    "                train.append(sample)\n",
    "\n",
    "    print('There are {} train, {} val, and {} bg noise samples'.format(len(train), len(val), len(bg_noise)))\n",
    "    return train, val, bg_noise\n",
    "\n",
    "trainset, valset, noiseset = load_data(DATADIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wav_read(fname):\n",
    "    wav, _ = librosa.load(fname, sr=None)\n",
    "    return wav\n",
    "\n",
    "def normalize_audio(wav):\n",
    "    return wav/max(wav)\n",
    "\n",
    "def time_shift(wav, shift):\n",
    "    start_ = int(shift)\n",
    "    if start_ >= 0:\n",
    "        wav_time_shift = np.r_[wav[start_:], np.random.uniform(-0.001,0.001, start_)]\n",
    "    else:\n",
    "        wav_time_shift = np.r_[np.random.uniform(-0.001,0.001, -start_), wav[:start_]]\n",
    "    return normalize_audio(wav_time_shift)\n",
    "\n",
    "def speed_change(wav, speed_rate):\n",
    "    # rate: lower is faster\n",
    "    wav_speed_tune = cv2.resize(wav, (1, int(len(wav) * speed_rate))).squeeze()\n",
    "    if len(wav_speed_tune) < 16000:\n",
    "        pad_len = 16000 - len(wav_speed_tune)\n",
    "        wav_speed_tune = np.r_[np.random.uniform(-0.001,0.001,int(pad_len/2.)),\n",
    "                               wav_speed_tune,\n",
    "                               np.random.uniform(-0.001,0.001,int(np.ceil(pad_len/2.)))]\n",
    "    else: \n",
    "        cut_len = len(wav_speed_tune) - 16000\n",
    "        wav_speed_tune = wav_speed_tune[int(cut_len/2.):int(cut_len/2.)+16000]\n",
    "    return normalize_audio(wav_speed_tune)\n",
    "\n",
    "def noise_add(wav, percent, ind):\n",
    "#     bg, sr = librosa.load(noiseset[ind], sr=None)\n",
    "    bg = wav_read(noiseset[ind])\n",
    "    bg = normalize_audio(bg)\n",
    "    start_ = np.random.randint(bg.shape[0]-16000)\n",
    "    bg_slice = bg[start_ : start_+16000]\n",
    "    wav_with_bg = wav * percent + bg_slice * (1-percent)\n",
    "    return normalize_audio(wav_with_bg)\n",
    "\n",
    "def get_spectrogram(wav):\n",
    "    v = 600\n",
    "    D = librosa.stft(wav, n_fft=v, hop_length=50,\n",
    "                     win_length=v, window='hamming')\n",
    "    spect, phase = librosa.magphase(D)\n",
    "    spect = scipy.ndimage.zoom(spect,1./7, order=1)\n",
    "    spect = spect.reshape(np.expand_dims(spect, axis=2).shape)\n",
    "    return spect\n",
    "\n",
    "def frange(x, y, jump):\n",
    "    while x < y:\n",
    "        yield x\n",
    "        x += jump\n",
    "        \n",
    "def all_aug(wav, params):\n",
    "    time, speed, noise_percent, noise_ind = params\n",
    "    aug = wav\n",
    "    aug = time_shift(aug, time)\n",
    "    aug = speed_change(wav, speed)\n",
    "    if noise_ind == -1:\n",
    "        aug = noise_add(aug, 1, noise_ind)\n",
    "    else:\n",
    "        aug = noise_add(aug, noise_percent, noise_ind)\n",
    "    return aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_spectrogram(wav):\n",
    "    v = 600\n",
    "    D = librosa.stft(wav, n_fft=v, hop_length=50,\n",
    "                     win_length=v, window='hamming')\n",
    "    spect, phase = librosa.magphase(D)\n",
    "    spect = scipy.ndimage.zoom(spect,1./7, order=1)\n",
    "#     spect = spect.reshape(np.expand_dims(spect, axis=2).shape)\n",
    "    return spect\n",
    "\n",
    "path = trainset[0][2]\n",
    "wav = wav_read(path)\n",
    "spec = get_spectrogram(wav)\n",
    "log_spect = np.log(spec)\n",
    "print('spectrogram shape:', log_spect.shape)\n",
    "plt.imshow(log_spect, aspect='auto', origin='lower',)\n",
    "plt.title('spectrogram of origin audio')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    }
   ],
   "source": [
    "DIV = 100\n",
    "def data_generator(data, params, mode='train'):\n",
    "    def generator():\n",
    "        count = 0\n",
    "        if mode == 'train':\n",
    "            np.random.shuffle(data)\n",
    "        \n",
    "        for (label_id, uid, fname) in data:\n",
    "            try:\n",
    "                wav = wav_read(fname)\n",
    "                wav = normalize_audio(wav)\n",
    "        \n",
    "                L = 16000  # be aware, some files are shorter than 1 sec!\n",
    "                if len(wav) < L:\n",
    "                    pad_len = L - len(wav)\n",
    "                    wav = np.r_[np.random.uniform(-0.001,0.001,int(pad_len/2.)),\n",
    "                                wav,\n",
    "                                np.random.uniform(-0.001,0.001,int(np.ceil(pad_len/2.)))]\n",
    "                elif len(wav) > L:\n",
    "                    cut_len = len(wav) - L\n",
    "                    wav = wav[int(cut_len/2.):int(cut_len/2.)+L]\n",
    "                    \n",
    "                if mode == 'train':\n",
    "                    \n",
    "                    variations = []\n",
    "\n",
    "                    time_shift_range = 4000\n",
    "                    for time in xrange(-time_shift_range, time_shift_range+1, 1000):\n",
    "                        for speed in frange(0.4,1.7,0.3):\n",
    "                            for noise_percentage in frange(0.2,1,0.1):\n",
    "                                for noise_ind in xrange(-1,len(noiseset)):\n",
    "                                    variation = [time, speed, noise_percentage, noise_ind]\n",
    "                                    variations.append(variation)\n",
    "\n",
    "                    len_var = len(variations)\n",
    "                    selected_indices = np.random.choice(len_var, int(len_var/DIV))\n",
    "\n",
    "                    for ind in selected_indices:\n",
    "                        yield dict(\n",
    "                            target=np.int32(label_id),\n",
    "                            wav=all_aug(wav, variations[ind])[:16000]\n",
    "                        )\n",
    "                else:\n",
    "                    yield dict(\n",
    "                        target=np.int32(label_id),\n",
    "                        wav=wav[:16000],\n",
    "                    )\n",
    "                                \n",
    "            except Exception as err:\n",
    "                print(err, label_id, uid, fname)\n",
    "\n",
    "    return generator\n",
    "\n",
    "class DataTracker(object):\n",
    "    def __init__(self, dataset):\n",
    "        self.data = dataset\n",
    "        gen = data_generator(dataset,[])\n",
    "        self.gen = gen()\n",
    "        self.count = 0\n",
    "    \n",
    "    def get_next_batch(self, size):\n",
    "        x,y = [], []\n",
    "        for i in tqdm(xrange(size)):\n",
    "            try:\n",
    "                data = next(self.gen)\n",
    "            except StopIteration:\n",
    "                print 'End of list'\n",
    "                break\n",
    "            \n",
    "            wav = data['wav']\n",
    "            val = get_spectrogram(wav)\n",
    "            x.append(val)\n",
    "            y.append(data['target'])\n",
    "        return np.array(x),np.array(y)\n",
    "    \n",
    "    def get_all_data(self):\n",
    "        return self.get_next_batch(len(self.data))\n",
    "try:\n",
    "    print'here'\n",
    "    train_x = np.load('train_x.npy')\n",
    "    train_y = np.load('train_y.npy')\n",
    "    valid_x = np.load('valid_x.npy')\n",
    "    valid_y = np.load('valid_y.npy')\n",
    "    \n",
    "except:\n",
    "    print'there'\n",
    "    traindata = DataTracker(trainset)\n",
    "    train_x, train_y = traindata.get_all_data()\n",
    "    train_y = np_utils.to_categorical(train_y)\n",
    "    np.save('train_x',train_x)\n",
    "    np.save('train_y',train_y)\n",
    "    \n",
    "    valdata = DataTracker(valset)\n",
    "    valid_x, valid_y = valdata.get_all_data()\n",
    "    valid_y = np_utils.to_categorical(valid_y)\n",
    "    np.save('valid_x',valid_x)\n",
    "    np.save('valid_y',valid_y)\n",
    "\n",
    "traingen = ImageDataGenerator()\n",
    "traingen.fit(train_x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add(a,b):\n",
    "    shape1 = backend.int_shape(a)\n",
    "    shape2 = backend.int_shape(b)\n",
    "    w = int(round(shape1[1]/shape2[1]))\n",
    "    h = int(round(shape1[2]/shape2[2]))\n",
    "    eq = shape1[3] == shape2[3]\n",
    "    \n",
    "    tmp = a\n",
    "    print w,h,eq\n",
    "    print shape1, shape2\n",
    "    if w>1 or h>1 or not eq:\n",
    "        tmp = Conv2D(filters=shape2[3],kernel_size=(1,1),strides=(w,h),padding='valid',kernel_initializer='he_normal', kernel_regularizer=l2(0.0001))(a)\n",
    "    print backend.int_shape(tmp)\n",
    "    print\n",
    "    return Add()([tmp, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tommy/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:1238: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/tommy/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/nn_impl.py:666: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "1 1 True\n",
      "(None, 22, 23, 128) (None, 22, 23, 128)\n",
      "(None, 22, 23, 128)\n",
      "\n",
      "1 1 True\n",
      "(None, 22, 23, 128) (None, 22, 23, 128)\n",
      "(None, 22, 23, 128)\n",
      "\n",
      "1 1 True\n",
      "(None, 22, 23, 128) (None, 22, 23, 128)\n",
      "(None, 22, 23, 128)\n",
      "\n",
      "1 1 True\n",
      "(None, 22, 23, 128) (None, 22, 23, 128)\n",
      "(None, 22, 23, 128)\n",
      "\n",
      "1 1 True\n",
      "(None, 22, 23, 128) (None, 22, 23, 128)\n",
      "(None, 22, 23, 128)\n",
      "\n",
      "1 1 True\n",
      "(None, 22, 23, 128) (None, 22, 23, 128)\n",
      "(None, 22, 23, 128)\n",
      "\n",
      "1 1 True\n",
      "(None, 22, 23, 128) (None, 22, 23, 128)\n",
      "(None, 22, 23, 128)\n",
      "\n",
      "1 1 True\n",
      "(None, 22, 23, 128) (None, 22, 23, 128)\n",
      "(None, 22, 23, 128)\n",
      "\n",
      "1 1 True\n",
      "(None, 22, 23, 128) (None, 22, 23, 128)\n",
      "(None, 22, 23, 128)\n",
      "\n",
      "1 1 True\n",
      "(None, 22, 23, 128) (None, 22, 23, 128)\n",
      "(None, 22, 23, 128)\n",
      "\n",
      "1 1 True\n",
      "(None, 22, 23, 128) (None, 22, 23, 128)\n",
      "(None, 22, 23, 128)\n",
      "\n",
      "1 1 True\n",
      "(None, 22, 23, 128) (None, 22, 23, 128)\n",
      "(None, 22, 23, 128)\n",
      "\n",
      "1 1 True\n",
      "(None, 22, 23, 128) (None, 22, 23, 128)\n",
      "(None, 22, 23, 128)\n",
      "\n",
      "1 1 True\n",
      "(None, 22, 23, 128) (None, 22, 23, 128)\n",
      "(None, 22, 23, 128)\n",
      "\n",
      "1 1 True\n",
      "(None, 22, 23, 128) (None, 22, 23, 128)\n",
      "(None, 22, 23, 128)\n",
      "\n",
      "1 1 True\n",
      "(None, 22, 23, 128) (None, 22, 23, 128)\n",
      "(None, 22, 23, 128)\n",
      "\n",
      "1 1 True\n",
      "(None, 22, 23, 128) (None, 22, 23, 128)\n",
      "(None, 22, 23, 128)\n",
      "\n",
      "1 1 True\n",
      "(None, 22, 23, 128) (None, 22, 23, 128)\n",
      "(None, 22, 23, 128)\n",
      "\n",
      "1 1 True\n",
      "(None, 22, 23, 128) (None, 22, 23, 128)\n",
      "(None, 22, 23, 128)\n",
      "\n",
      "1 1 True\n",
      "(None, 22, 23, 128) (None, 22, 23, 128)\n",
      "(None, 22, 23, 128)\n",
      "\n",
      "WARNING:tensorflow:From /home/tommy/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:1255: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "def layer(num_filt, size, strides, inp):\n",
    "    tmp = BatchNormalization(axis=3)(inp)\n",
    "    tmp = Activation('relu')(tmp)\n",
    "    tmp = Conv2D(num_filt, size, strides=strides, padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0001))(tmp)\n",
    "    return tmp\n",
    "\n",
    "l = Input(train_x.shape[1:])\n",
    "\n",
    "x = Conv2D(128, (7,7), strides=2, padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0001))(l)\n",
    "x = BatchNormalization(axis=3)(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "#first layer\n",
    "num = 32\n",
    "xtmp = Conv2D(num, (1,1), strides=1, \n",
    "              padding='same', \n",
    "              kernel_initializer='he_normal', \n",
    "              kernel_regularizer=l2(0.0001))(x)\n",
    "xtmp = layer(num, (3,3), 1, xtmp)\n",
    "xtmp = layer(num*4, (1,1), 1, xtmp)\n",
    "\n",
    "x = add(x,xtmp)\n",
    "\n",
    "#other layer\n",
    "xtmp = layer(num, (1,1), 1, x)\n",
    "xtmp = layer(num, (3,3), 1, xtmp)\n",
    "xtmp = layer(num*4, (1,1), 1, xtmp)\n",
    "x = add(x,xtmp)\n",
    "\n",
    "for i in xrange(9):\n",
    "    xtmp = layer(num, (1,1), 1, x)\n",
    "    xtmp = layer(num, (3,3), 1, xtmp)\n",
    "    xtmp = layer(num*4, (1,1), 1, xtmp)\n",
    "    x = add(x,xtmp)\n",
    "\n",
    "    #other layer\n",
    "    xtmp = layer(num, (1,1), 1, x)\n",
    "    xtmp = layer(num, (3,3), 1, xtmp)\n",
    "    xtmp = layer(num*4, (1,1), 1, xtmp)\n",
    "    x = add(x,xtmp)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "xshape = backend.int_shape(x)\n",
    "x = AveragePooling2D(pool_size=(xshape[1],xshape[2]), strides=(1,1))(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(len(POSSIBLE_LABELS), activation='softmax', kernel_initializer='he_normal', kernel_regularizer=l2(0.0001))(x)\n",
    "\n",
    "early=EarlyStopping(monitor='val_acc', patience=15, verbose=1, mode='auto')\n",
    "filepath=\"weights-with-augmentation-val-acc-lr.best.hdf5\"\n",
    "checkpoint=ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), monitor='val_acc', cooldown=0, patience=5, min_lr=0.5e-6, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 43, 46, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 22, 23, 128)  6400        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 22, 23, 128)  512         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 22, 23, 128)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 22, 23, 32)   4128        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 22, 23, 32)   128         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 22, 23, 32)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 22, 23, 32)   9248        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 22, 23, 32)   128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 22, 23, 32)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 22, 23, 128)  4224        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 22, 23, 128)  0           activation_1[0][0]               \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 22, 23, 128)  512         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 22, 23, 128)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 22, 23, 32)   4128        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 22, 23, 32)   128         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 22, 23, 32)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 22, 23, 32)   9248        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 22, 23, 32)   128         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 22, 23, 32)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 22, 23, 128)  4224        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 22, 23, 128)  0           add_1[0][0]                      \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 22, 23, 128)  512         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 22, 23, 128)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 22, 23, 32)   4128        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 22, 23, 32)   128         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 22, 23, 32)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 22, 23, 32)   9248        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 22, 23, 32)   128         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 22, 23, 32)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 22, 23, 128)  4224        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 22, 23, 128)  0           add_2[0][0]                      \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 22, 23, 128)  512         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 22, 23, 128)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 22, 23, 32)   4128        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 22, 23, 32)   128         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 22, 23, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 22, 23, 32)   9248        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 22, 23, 32)   128         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 22, 23, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 22, 23, 128)  4224        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 22, 23, 128)  0           add_3[0][0]                      \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 22, 23, 128)  512         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 22, 23, 128)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 22, 23, 32)   4128        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 22, 23, 32)   128         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 22, 23, 32)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 22, 23, 32)   9248        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 22, 23, 32)   128         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 22, 23, 32)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 22, 23, 128)  4224        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 22, 23, 128)  0           add_4[0][0]                      \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 22, 23, 128)  512         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 22, 23, 128)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 22, 23, 32)   4128        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 22, 23, 32)   128         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 22, 23, 32)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 22, 23, 32)   9248        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 22, 23, 32)   128         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 22, 23, 32)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 22, 23, 128)  4224        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 22, 23, 128)  0           add_5[0][0]                      \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 22, 23, 128)  512         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 22, 23, 128)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 22, 23, 32)   4128        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 22, 23, 32)   128         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 22, 23, 32)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 22, 23, 32)   9248        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 22, 23, 32)   128         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 22, 23, 32)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 22, 23, 128)  4224        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 22, 23, 128)  0           add_6[0][0]                      \n",
      "                                                                 conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 22, 23, 128)  512         add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 22, 23, 128)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 22, 23, 32)   4128        activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 22, 23, 32)   128         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 22, 23, 32)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 22, 23, 32)   9248        activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 22, 23, 32)   128         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 22, 23, 32)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 22, 23, 128)  4224        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 22, 23, 128)  0           add_7[0][0]                      \n",
      "                                                                 conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 22, 23, 128)  512         add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 22, 23, 128)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 22, 23, 32)   4128        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 22, 23, 32)   128         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 22, 23, 32)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 22, 23, 32)   9248        activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 22, 23, 32)   128         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 22, 23, 32)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 22, 23, 128)  4224        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 22, 23, 128)  0           add_8[0][0]                      \n",
      "                                                                 conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 22, 23, 128)  512         add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 22, 23, 128)  0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 22, 23, 32)   4128        activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 22, 23, 32)   128         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 22, 23, 32)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 22, 23, 32)   9248        activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 22, 23, 32)   128         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 22, 23, 32)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 22, 23, 128)  4224        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 22, 23, 128)  0           add_9[0][0]                      \n",
      "                                                                 conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 22, 23, 128)  512         add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 22, 23, 128)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 22, 23, 32)   4128        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 22, 23, 32)   128         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 22, 23, 32)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 22, 23, 32)   9248        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 22, 23, 32)   128         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 22, 23, 32)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 22, 23, 128)  4224        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 22, 23, 128)  0           add_10[0][0]                     \n",
      "                                                                 conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 22, 23, 128)  512         add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 22, 23, 128)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 22, 23, 32)   4128        activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 22, 23, 32)   128         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 22, 23, 32)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 22, 23, 32)   9248        activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 22, 23, 32)   128         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 22, 23, 32)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 22, 23, 128)  4224        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 22, 23, 128)  0           add_11[0][0]                     \n",
      "                                                                 conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 22, 23, 128)  512         add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 22, 23, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 22, 23, 32)   4128        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 22, 23, 32)   128         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 22, 23, 32)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 22, 23, 32)   9248        activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 22, 23, 32)   128         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 22, 23, 32)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 22, 23, 128)  4224        activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 22, 23, 128)  0           add_12[0][0]                     \n",
      "                                                                 conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 22, 23, 128)  512         add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 22, 23, 128)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 22, 23, 32)   4128        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 22, 23, 32)   128         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 22, 23, 32)   0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 22, 23, 32)   9248        activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 22, 23, 32)   128         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 22, 23, 32)   0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 22, 23, 128)  4224        activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 22, 23, 128)  0           add_13[0][0]                     \n",
      "                                                                 conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 22, 23, 128)  512         add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 22, 23, 128)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 22, 23, 32)   4128        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 22, 23, 32)   128         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 22, 23, 32)   0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 22, 23, 32)   9248        activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 22, 23, 32)   128         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 22, 23, 32)   0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 22, 23, 128)  4224        activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 22, 23, 128)  0           add_14[0][0]                     \n",
      "                                                                 conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 22, 23, 128)  512         add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 22, 23, 128)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 22, 23, 32)   4128        activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 22, 23, 32)   128         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 22, 23, 32)   0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 22, 23, 32)   9248        activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 22, 23, 32)   128         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 22, 23, 32)   0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 22, 23, 128)  4224        activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 22, 23, 128)  0           add_15[0][0]                     \n",
      "                                                                 conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 22, 23, 128)  512         add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 22, 23, 128)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 22, 23, 32)   4128        activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 22, 23, 32)   128         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 22, 23, 32)   0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 22, 23, 32)   9248        activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 22, 23, 32)   128         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 22, 23, 32)   0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 22, 23, 128)  4224        activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 22, 23, 128)  0           add_16[0][0]                     \n",
      "                                                                 conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 22, 23, 128)  512         add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 22, 23, 128)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 22, 23, 32)   4128        activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 22, 23, 32)   128         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 22, 23, 32)   0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 22, 23, 32)   9248        activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 22, 23, 32)   128         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 22, 23, 32)   0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 22, 23, 128)  4224        activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 22, 23, 128)  0           add_17[0][0]                     \n",
      "                                                                 conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 22, 23, 128)  512         add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 22, 23, 128)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 22, 23, 32)   4128        activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 22, 23, 32)   128         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 22, 23, 32)   0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 22, 23, 32)   9248        activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 22, 23, 32)   128         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 22, 23, 32)   0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 22, 23, 128)  4224        activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 22, 23, 128)  0           add_18[0][0]                     \n",
      "                                                                 conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 22, 23, 128)  512         add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 22, 23, 128)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 22, 23, 32)   4128        activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 22, 23, 32)   128         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 22, 23, 32)   0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 22, 23, 32)   9248        activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 22, 23, 32)   128         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 22, 23, 32)   0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 22, 23, 128)  4224        activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 22, 23, 128)  0           add_19[0][0]                     \n",
      "                                                                 conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 22, 23, 128)  512         add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 22, 23, 128)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 1, 1, 128)    0           activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 128)          0           average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 12)           1548        flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 375,820\n",
      "Trainable params: 367,884\n",
      "Non-trainable params: 7,936\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(l,x)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "      loss='categorical_crossentropy',\n",
    "      metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1809/1810 [============================>.] - ETA: 3s - loss: 1.6800 - acc: 0.6259Epoch 00001: val_acc improved from -inf to 0.59576, saving model to weights-with-augmentation-val-acc-lr.best.hdf5\n",
      "1810/1810 [==============================] - 6100s 3s/step - loss: 1.6799 - acc: 0.6259 - val_loss: 1.5405 - val_acc: 0.5958\n",
      "Epoch 2/200\n",
      "1809/1810 [============================>.] - ETA: 2s - loss: 1.1538 - acc: 0.6985Epoch 00002: val_acc did not improve\n",
      "1810/1810 [==============================] - 5176s 3s/step - loss: 1.1540 - acc: 0.6985 - val_loss: 1.4613 - val_acc: 0.5952\n",
      "Epoch 3/200\n",
      "1809/1810 [============================>.] - ETA: 2s - loss: 0.9949 - acc: 0.7415Epoch 00003: val_acc improved from 0.59576 to 0.64372, saving model to weights-with-augmentation-val-acc-lr.best.hdf5\n",
      "1810/1810 [==============================] - 4486s 2s/step - loss: 0.9950 - acc: 0.7415 - val_loss: 1.3303 - val_acc: 0.6437\n",
      "Epoch 4/200\n",
      "1809/1810 [============================>.] - ETA: 2s - loss: 0.9085 - acc: 0.7658Epoch 00004: val_acc improved from 0.64372 to 0.68020, saving model to weights-with-augmentation-val-acc-lr.best.hdf5\n",
      "1810/1810 [==============================] - 4421s 2s/step - loss: 0.9085 - acc: 0.7658 - val_loss: 1.2107 - val_acc: 0.6802\n",
      "Epoch 5/200\n",
      "1809/1810 [============================>.] - ETA: 2s - loss: 0.8505 - acc: 0.7864Epoch 00005: val_acc improved from 0.68020 to 0.69741, saving model to weights-with-augmentation-val-acc-lr.best.hdf5\n",
      "1810/1810 [==============================] - 4535s 3s/step - loss: 0.8505 - acc: 0.7865 - val_loss: 1.1046 - val_acc: 0.6974\n",
      "Epoch 6/200\n",
      "1809/1810 [============================>.] - ETA: 2s - loss: 0.8078 - acc: 0.8006Epoch 00006: val_acc did not improve\n",
      "1810/1810 [==============================] - 4403s 2s/step - loss: 0.8078 - acc: 0.8006 - val_loss: 1.2611 - val_acc: 0.6317\n",
      "Epoch 7/200\n",
      "1809/1810 [============================>.] - ETA: 2s - loss: 0.7745 - acc: 0.8105Epoch 00007: val_acc did not improve\n",
      "1810/1810 [==============================] - 4495s 2s/step - loss: 0.7745 - acc: 0.8105 - val_loss: 1.1857 - val_acc: 0.6914\n",
      "Epoch 8/200\n",
      "1809/1810 [============================>.] - ETA: 2s - loss: 0.7403 - acc: 0.8228Epoch 00008: val_acc did not improve\n",
      "1810/1810 [==============================] - 4491s 2s/step - loss: 0.7403 - acc: 0.8229 - val_loss: 1.3665 - val_acc: 0.6530\n",
      "Epoch 9/200\n",
      "1809/1810 [============================>.] - ETA: 2s - loss: 0.7181 - acc: 0.8319Epoch 00009: val_acc did not improve\n",
      "1810/1810 [==============================] - 4561s 3s/step - loss: 0.7181 - acc: 0.8319 - val_loss: 1.2066 - val_acc: 0.6861\n",
      "Epoch 10/200\n",
      "1809/1810 [============================>.] - ETA: 2s - loss: 0.7015 - acc: 0.8384Epoch 00010: val_acc did not improve\n",
      "1810/1810 [==============================] - 4596s 3s/step - loss: 0.7014 - acc: 0.8384 - val_loss: 1.2759 - val_acc: 0.6637\n",
      "Epoch 11/200\n",
      "1809/1810 [============================>.] - ETA: 2s - loss: 0.6792 - acc: 0.8468Epoch 00011: val_acc did not improve\n",
      "1810/1810 [==============================] - 4675s 3s/step - loss: 0.6792 - acc: 0.8468 - val_loss: 1.5996 - val_acc: 0.6146\n",
      "Epoch 12/200\n",
      "1809/1810 [============================>.] - ETA: 2s - loss: 0.5500 - acc: 0.8893Epoch 00012: val_acc did not improve\n",
      "1810/1810 [==============================] - 4793s 3s/step - loss: 0.5500 - acc: 0.8893 - val_loss: 1.2625 - val_acc: 0.6927\n",
      "Epoch 13/200\n",
      "1809/1810 [============================>.] - ETA: 2s - loss: 0.5034 - acc: 0.9023Epoch 00013: val_acc improved from 0.69741 to 0.72080, saving model to weights-with-augmentation-val-acc-lr.best.hdf5\n",
      "1810/1810 [==============================] - 4904s 3s/step - loss: 0.5034 - acc: 0.9023 - val_loss: 1.1850 - val_acc: 0.7208\n",
      "Epoch 14/200\n",
      "1809/1810 [============================>.] - ETA: 2s - loss: 0.4826 - acc: 0.9079Epoch 00014: val_acc improved from 0.72080 to 0.72801, saving model to weights-with-augmentation-val-acc-lr.best.hdf5\n",
      "1810/1810 [==============================] - 5556s 3s/step - loss: 0.4825 - acc: 0.9079 - val_loss: 1.1640 - val_acc: 0.7280\n",
      "Epoch 15/200\n",
      "1809/1810 [============================>.] - ETA: 2s - loss: 0.4629 - acc: 0.9120Epoch 00015: val_acc did not improve\n",
      "1810/1810 [==============================] - 4658s 3s/step - loss: 0.4630 - acc: 0.9120 - val_loss: 1.2948 - val_acc: 0.6876\n",
      "Epoch 16/200\n",
      "1809/1810 [============================>.] - ETA: 2s - loss: 0.4449 - acc: 0.9165Epoch 00016: val_acc did not improve\n",
      "1810/1810 [==============================] - 4677s 3s/step - loss: 0.4450 - acc: 0.9165 - val_loss: 1.4617 - val_acc: 0.6467\n",
      "Epoch 17/200\n",
      "1809/1810 [============================>.] - ETA: 2s - loss: 0.4313 - acc: 0.9193Epoch 00017: val_acc did not improve\n",
      "1810/1810 [==============================] - 4845s 3s/step - loss: 0.4312 - acc: 0.9193 - val_loss: 1.2983 - val_acc: 0.7030\n",
      "Epoch 18/200\n",
      "1809/1810 [============================>.] - ETA: 2s - loss: 0.4168 - acc: 0.9243Epoch 00018: val_acc did not improve\n",
      "1810/1810 [==============================] - 5239s 3s/step - loss: 0.4168 - acc: 0.9243 - val_loss: 1.3290 - val_acc: 0.7108\n",
      "Epoch 19/200\n",
      "1809/1810 [============================>.] - ETA: 2s - loss: 0.4058 - acc: 0.9261Epoch 00019: val_acc did not improve\n",
      "1810/1810 [==============================] - 5194s 3s/step - loss: 0.4059 - acc: 0.9260 - val_loss: 1.4038 - val_acc: 0.6808\n",
      "Epoch 20/200\n",
      "1809/1810 [============================>.] - ETA: 3s - loss: 0.3972 - acc: 0.9289Epoch 00020: val_acc did not improve\n",
      "1810/1810 [==============================] - 6166s 3s/step - loss: 0.3975 - acc: 0.9288 - val_loss: 1.4635 - val_acc: 0.6976\n",
      "Epoch 21/200\n",
      "1809/1810 [============================>.] - ETA: 3s - loss: 0.3389 - acc: 0.9481Epoch 00021: val_acc did not improve\n",
      "1810/1810 [==============================] - 5727s 3s/step - loss: 0.3390 - acc: 0.9481 - val_loss: 1.3800 - val_acc: 0.6965\n",
      "Epoch 22/200\n",
      "1809/1810 [============================>.] - ETA: 2s - loss: 0.3187 - acc: 0.9540Epoch 00022: val_acc did not improve\n",
      "1810/1810 [==============================] - 4619s 3s/step - loss: 0.3188 - acc: 0.9539 - val_loss: 1.4432 - val_acc: 0.7064\n",
      "Epoch 23/200\n",
      "1809/1810 [============================>.] - ETA: 2s - loss: 0.3077 - acc: 0.9565Epoch 00023: val_acc did not improve\n",
      "1810/1810 [==============================] - 4653s 3s/step - loss: 0.3078 - acc: 0.9564 - val_loss: 1.5069 - val_acc: 0.7006\n",
      "Epoch 24/200\n",
      "1809/1810 [============================>.] - ETA: 2s - loss: 0.3003 - acc: 0.9578Epoch 00024: val_acc did not improve\n",
      "1810/1810 [==============================] - 4549s 3s/step - loss: 0.3004 - acc: 0.9578 - val_loss: 1.5082 - val_acc: 0.7015\n",
      "Epoch 25/200\n",
      "1809/1810 [============================>.] - ETA: 2s - loss: 0.2921 - acc: 0.9597Epoch 00025: val_acc did not improve\n",
      "1810/1810 [==============================] - 4685s 3s/step - loss: 0.2921 - acc: 0.9597 - val_loss: 1.6199 - val_acc: 0.6808\n",
      "Epoch 26/200\n",
      "1809/1810 [============================>.] - ETA: 2s - loss: 0.2723 - acc: 0.9661Epoch 00026: val_acc did not improve\n",
      "1810/1810 [==============================] - 4636s 3s/step - loss: 0.2723 - acc: 0.9661 - val_loss: 1.5842 - val_acc: 0.6998\n",
      "Epoch 27/200\n",
      "1809/1810 [============================>.] - ETA: 2s - loss: 0.2649 - acc: 0.9689Epoch 00027: val_acc did not improve\n",
      "1810/1810 [==============================] - 4781s 3s/step - loss: 0.2648 - acc: 0.9689 - val_loss: 1.5837 - val_acc: 0.7096\n",
      "Epoch 28/200\n",
      "1809/1810 [============================>.] - ETA: 3s - loss: 0.2586 - acc: 0.9702Epoch 00028: val_acc did not improve\n",
      "1810/1810 [==============================] - 5721s 3s/step - loss: 0.2586 - acc: 0.9702 - val_loss: 1.6248 - val_acc: 0.7095\n",
      "Epoch 29/200\n",
      "1809/1810 [============================>.] - ETA: 3s - loss: 0.2556 - acc: 0.9707Epoch 00029: val_acc did not improve\n",
      "1810/1810 [==============================] - 6378s 4s/step - loss: 0.2556 - acc: 0.9707 - val_loss: 1.6409 - val_acc: 0.7030\n",
      "Epoch 00029: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(traingen.flow(train_x, train_y, batch_size=32),\n",
    "                              steps_per_epoch=train_x.shape[0]//32, \n",
    "                              validation_data=(valid_x,valid_y),\n",
    "                              epochs=200, \n",
    "                              verbose=1, \n",
    "                              max_queue_size=128,\n",
    "                              shuffle=True,\n",
    "                              callbacks=[checkpoint, early, lr_reducer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('my_model_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\t\t\t    train_x.npy\r\n",
      "model-k\t\t\t    train_y.npy\r\n",
      "my_model_test.h5\t    valid_x.npy\r\n",
      "speech_contest-Copy1.ipynb  valid_y.npy\r\n",
      "speech_contest.ipynb\t    weights-with-augmentation-val-acc-lr.best.hdf5\r\n",
      "speech_contestpre.ipynb     working.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.evaluate(x_test, y_test, batch_size=512)\n",
    "print('Loss: %.2f Accuracy: %.2f%%' % (res[0], res[1]*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nARaFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7f52e9fc10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7f387da990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = test_data_generator(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sample': 'clip_a0f0fc92b.wav',\n",
       " 'wav': array([  6.10370189e-05,   9.15555283e-05,   9.15555283e-05, ...,\n",
       "          0.00000000e+00,   3.05185094e-05,   1.52592547e-04], dtype=float32)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(g())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/158538 [00:00<27:33, 95.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "there\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158538/158538 [30:11<00:00, 87.53it/s]\n"
     ]
    }
   ],
   "source": [
    "paths = glob(os.path.join(DATADIR, 'test/audio/*wav'))\n",
    "\n",
    "def test_data_generator(data):\n",
    "    def generator():\n",
    "        for path in data:\n",
    "            _, wav = wavfile.read(path)\n",
    "            wav = wav.astype(np.float32) / np.iinfo(np.int16).max\n",
    "            fname = os.path.basename(path)\n",
    "            yield dict(\n",
    "                sample=np.string_(fname),\n",
    "                wav=wav,\n",
    "            )\n",
    "\n",
    "    return generator\n",
    "\n",
    "class DataTrackerTest(object):\n",
    "    def __init__(self, dataset):\n",
    "        self.data = dataset\n",
    "        gen = test_data_generator(dataset)\n",
    "        self.gen = gen()\n",
    "        self.count = 0\n",
    "    \n",
    "    def get_next_batch(self, size):\n",
    "        x,y = [], []\n",
    "        for i in tqdm(xrange(size)):\n",
    "            try:\n",
    "                data = next(self.gen)\n",
    "            except StopIteration:\n",
    "                print 'End of list'\n",
    "                break\n",
    "            \n",
    "            wav = data['wav']\n",
    "            val = get_spectrogram(wav)\n",
    "            x.append(val)\n",
    "            y.append(data['sample'])\n",
    "        return np.array(x),np.array(y)\n",
    "    \n",
    "    def get_all_data(self):\n",
    "        return self.get_next_batch(len(self.data))\n",
    "    \n",
    "try:\n",
    "    print'here'\n",
    "    test_x = np.load('test_x.npy')\n",
    "    test_y = np.load('test_y.npy')\n",
    "    \n",
    "except:\n",
    "    print'there'\n",
    "    testdata = DataTrackerTest(paths)\n",
    "    test_x, test_y = testdata.get_all_data()\n",
    "    np.save('test_x',test_x)\n",
    "    np.save('test_y',test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158538/158538 [==============================] - 4952s 31ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_x, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.99646720e-07,   8.53457607e-07,   5.33995353e-06, ...,\n",
       "          9.89262617e-07,   1.27792868e-04,   9.92457747e-01],\n",
       "       [  3.41562327e-07,   3.19234314e-05,   4.11992287e-03, ...,\n",
       "          1.85912722e-04,   1.38789910e-05,   9.92701173e-01],\n",
       "       [  1.20508004e-04,   1.34414004e-05,   1.67195909e-02, ...,\n",
       "          1.38501546e-05,   5.05980046e-04,   1.71639502e-01],\n",
       "       ..., \n",
       "       [  1.57164104e-04,   8.82957422e-04,   2.76349545e-01, ...,\n",
       "          8.78970081e-04,   5.34472347e-04,   6.05936706e-01],\n",
       "       [  1.93349861e-05,   3.44250118e-04,   5.03925083e-04, ...,\n",
       "          4.67266582e-05,   1.74164976e-04,   2.75589917e-02],\n",
       "       [  9.87832209e-06,   3.19755782e-04,   1.41317248e-01, ...,\n",
       "          1.20244804e-03,   9.31373361e-05,   8.54961634e-01]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158538/158538 [00:00<00:00, 1195556.50it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dir = OUTDIR\n",
    "submission = dict()\n",
    "\n",
    "for p,n in tqdm(zip(pred, test_y)):\n",
    "    submission[n] = id2name[p]\n",
    "    \n",
    "with open(os.path.join(model_dir, 'submission.csv'), 'w') as fout:\n",
    "    fout.write('fname,label\\n')\n",
    "    for fname, label in submission.items():\n",
    "        fout.write('{},{}\\n'.format(fname, label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
