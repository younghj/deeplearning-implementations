{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from os.path import isdir, join\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Math\n",
    "import numpy as np\n",
    "from scipy.fftpack import fft\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import scipy\n",
    "import librosa\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import IPython.display as ipd\n",
    "import librosa.display\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "import pandas as pd\n",
    "from tensorflow.contrib import signal\n",
    "\n",
    "import python_speech_features\n",
    "\n",
    "# Data Loading\n",
    "import re\n",
    "from glob import glob\n",
    "\n",
    "# Prediction\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Layers\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import layers\n",
    "from tensorflow.contrib.framework import arg_scope\n",
    "from tflearn.layers.conv import global_avg_pool\n",
    "from tensorflow.contrib.layers import batch_norm, flatten\n",
    "\n",
    "# it's a magic function :)\n",
    "# Training\n",
    "from tensorflow.contrib.learn.python.learn.learn_io.generator_io import generator_input_fn\n",
    "\n",
    "import cv2\n",
    "\n",
    "\n",
    "# #KERAS\n",
    "\n",
    "# import os\n",
    "# os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "# # os.environ[\"THEANO_FLAGS\"] = \"mode=FAST_RUN,device=gpu,floatX=float32\"\n",
    "\n",
    "# import keras\n",
    "# import numpy as np\n",
    "# from keras.models import Model, load_model\n",
    "# from keras.layers import Dense, Input, Activation, Flatten, Add\n",
    "# from keras.layers import BatchNormalization\n",
    "# from keras.regularizers import l2\n",
    "# from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# from keras.datasets import cifar10\n",
    "# from keras.utils import np_utils\n",
    "# from keras.layers.convolutional import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# from keras import backend\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 57929 train, 6798 val, and 6 bg noise samples\n"
     ]
    }
   ],
   "source": [
    "DATADIR = './data' # unzipped train and test data\n",
    "OUTDIR = './model-k' # just a random name\n",
    "\n",
    "POSSIBLE_LABELS = 'yes no up down left right on off stop go silence unknown'.split()\n",
    "id2name = {i: name for i, name in enumerate(POSSIBLE_LABELS)}\n",
    "name2id = {name: i for i, name in id2name.items()}\n",
    "\n",
    "\n",
    "def load_data(data_dir):\n",
    "    \"\"\" Return 2 lists of tuples:\n",
    "    [(class_id, user_id, path), ...] for train\n",
    "    [(class_id, user_id, path), ...] for validation\n",
    "    \"\"\"\n",
    "    # Just a simple regexp for paths with three groups:\n",
    "    # prefix, label, user_id\n",
    "    pattern = re.compile(\"(.+\\/)?(\\w+)\\/([^_]+)_.+wav\")\n",
    "    all_files = glob(os.path.join(data_dir, 'train/audio/*/*wav'))\n",
    "\n",
    "    with open(os.path.join(data_dir, 'train/validation_list.txt'), 'r') as fin:\n",
    "        validation_files = fin.readlines()\n",
    "    valset = set()\n",
    "    for entry in validation_files:\n",
    "        r = re.match(pattern, entry)\n",
    "        if r:\n",
    "            valset.add(r.group(3))\n",
    "\n",
    "    possible = set(POSSIBLE_LABELS)\n",
    "    train, val, bg_noise = [], [], []\n",
    "    for entry in all_files:\n",
    "        r = re.match(pattern, entry)\n",
    "        if r:\n",
    "            label, uid = r.group(2), r.group(3)\n",
    "            if label == '_background_noise_':\n",
    "                bg_noise.append(entry)\n",
    "                label = 'silence'\n",
    "            if label not in possible:\n",
    "                label = 'unknown'\n",
    "\n",
    "            label_id = name2id[label]\n",
    "\n",
    "            sample = (label_id, uid, entry)\n",
    "            if uid in valset:\n",
    "                val.append(sample)\n",
    "            else:\n",
    "                train.append(sample)\n",
    "\n",
    "    print('There are {} train, {} val, and {} bg noise samples'.format(len(train), len(val), len(bg_noise)))\n",
    "    return train, val, bg_noise\n",
    "\n",
    "trainset, valset, noiseset = load_data(DATADIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wav_read(fname):\n",
    "    wav, _ = librosa.load(fname, sr=None)\n",
    "    return wav\n",
    "\n",
    "def normalize_audio(wav):\n",
    "    return wav/max(wav)\n",
    "\n",
    "def time_shift(wav, shift):\n",
    "    start_ = int(shift)\n",
    "    if start_ >= 0:\n",
    "        wav_time_shift = np.r_[wav[start_:], np.random.uniform(-0.001,0.001, start_)]\n",
    "    else:\n",
    "        wav_time_shift = np.r_[np.random.uniform(-0.001,0.001, -start_), wav[:start_]]\n",
    "    return normalize_audio(wav_time_shift)\n",
    "\n",
    "def speed_change(wav, speed_rate):\n",
    "    # rate: lower is faster\n",
    "    wav_speed_tune = cv2.resize(wav, (1, int(len(wav) * speed_rate))).squeeze()\n",
    "    if len(wav_speed_tune) < 16000:\n",
    "        pad_len = 16000 - len(wav_speed_tune)\n",
    "        wav_speed_tune = np.r_[np.random.uniform(-0.001,0.001,int(pad_len/2.)),\n",
    "                               wav_speed_tune,\n",
    "                               np.random.uniform(-0.001,0.001,int(np.ceil(pad_len/2.)))]\n",
    "    else: \n",
    "        cut_len = len(wav_speed_tune) - 16000\n",
    "        wav_speed_tune = wav_speed_tune[int(cut_len/2.):int(cut_len/2.)+16000]\n",
    "    return normalize_audio(wav_speed_tune)\n",
    "\n",
    "def noise_add(wav, percent, ind):\n",
    "#     bg, sr = librosa.load(noiseset[ind], sr=None)\n",
    "    bg = wav_read(noiseset[ind])\n",
    "    bg = normalize_audio(bg)\n",
    "    start_ = np.random.randint(bg.shape[0]-16000)\n",
    "    bg_slice = bg[start_ : start_+16000]\n",
    "    wav_with_bg = wav * percent + bg_slice * (1-percent)\n",
    "    return normalize_audio(wav_with_bg)\n",
    "\n",
    "def get_spectrogram(wav):\n",
    "    v = 600\n",
    "    D = librosa.stft(wav, n_fft=v, hop_length=50,\n",
    "                     win_length=v, window='hamming')\n",
    "    spect, phase = librosa.magphase(D)\n",
    "    spect = scipy.ndimage.zoom(spect,1./7, order=1)\n",
    "    spect = spect.reshape(np.expand_dims(spect, axis=2).shape)\n",
    "    return spect\n",
    "\n",
    "def frange(x, y, jump):\n",
    "    while x < y:\n",
    "        yield x\n",
    "        x += jump\n",
    "        \n",
    "def all_aug(wav, params):\n",
    "    time, speed, noise_percent, noise_ind = params\n",
    "    aug = wav\n",
    "    aug = time_shift(aug, time)\n",
    "    aug = speed_change(wav, speed)\n",
    "    if noise_ind == -1:\n",
    "        aug = noise_add(aug, 1, noise_ind)\n",
    "    else:\n",
    "        aug = noise_add(aug, noise_percent, noise_ind)\n",
    "    return aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DIV = 100\n",
    "def data_generator(data, params, mode='train'):\n",
    "    def generator():\n",
    "        count = 0\n",
    "        if mode == 'train':\n",
    "            np.random.shuffle(data)\n",
    "        \n",
    "        for (label_id, uid, fname) in data:\n",
    "            try:\n",
    "                wav = wav_read(fname)\n",
    "                wav = normalize_audio(wav)\n",
    "        \n",
    "                L = 16000  # be aware, some files are shorter than 1 sec!\n",
    "                if len(wav) < L:\n",
    "                    pad_len = L - len(wav)\n",
    "                    wav = np.r_[np.random.uniform(-0.001,0.001,int(pad_len/2.)),\n",
    "                                wav,\n",
    "                                np.random.uniform(-0.001,0.001,int(np.ceil(pad_len/2.)))]\n",
    "                elif len(wav) > L:\n",
    "                    cut_len = len(wav) - L\n",
    "                    wav = wav[int(cut_len/2.):int(cut_len/2.)+L]\n",
    "                    \n",
    "                if mode == 'train':\n",
    "                    \n",
    "                    variations = []\n",
    "\n",
    "                    time_shift_range = 4000\n",
    "                    for time in xrange(-time_shift_range, time_shift_range+1, 1000):\n",
    "                        for speed in frange(0.4,1.7,0.3):\n",
    "                            for noise_percentage in frange(0.2,1,0.1):\n",
    "                                for noise_ind in xrange(-1,len(noiseset)):\n",
    "                                    variation = [time, speed, noise_percentage, noise_ind]\n",
    "                                    variations.append(variation)\n",
    "\n",
    "                    len_var = len(variations)\n",
    "                    selected_indices = np.random.choice(len_var, int(len_var/DIV))\n",
    "\n",
    "                    for ind in selected_indices:\n",
    "                        yield dict(\n",
    "                            target=np.int32(label_id),\n",
    "                            wav=all_aug(wav, variations[ind])[:16000]\n",
    "                        )\n",
    "                else:\n",
    "                    yield dict(\n",
    "                        target=np.int32(label_id),\n",
    "                        wav=wav[:16000],\n",
    "                    )\n",
    "                                \n",
    "            except Exception as err:\n",
    "                print(err, label_id, uid, fname)\n",
    "\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import layers\n",
    "\n",
    "def baseline(x, params, is_training):\n",
    "    x = layers.batch_norm(x, is_training=is_training)\n",
    "    for i in range(4):\n",
    "        x = layers.conv2d(\n",
    "            x, 16 * (2 ** i), 3, 1,\n",
    "            activation_fn=tf.nn.elu,\n",
    "            normalizer_fn=layers.batch_norm if params.use_batch_norm else None,\n",
    "            normalizer_params={'is_training': is_training}\n",
    "        )\n",
    "        x = layers.max_pool2d(x, 2, 2)\n",
    "\n",
    "    # just take two kind of pooling and then mix them, why not :)\n",
    "    mpool = tf.reduce_max(x, axis=[1, 2], keep_dims=True)\n",
    "    apool = tf.reduce_mean(x, axis=[1, 2], keep_dims=True)\n",
    "\n",
    "    x = 0.5 * (mpool + apool)\n",
    "    # we can use conv2d 1x1 instead of dense\n",
    "    x = layers.conv2d(x, 128, 1, 1, activation_fn=tf.nn.elu)\n",
    "    x = tf.nn.dropout(x, keep_prob=params.keep_prob if is_training else 1.0)\n",
    "    \n",
    "    # again conv2d 1x1 instead of dense layer\n",
    "    logits = layers.conv2d(x, params.num_classes, 1, 1, activation_fn=None)\n",
    "    return tf.squeeze(logits, [1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib import signal\n",
    "\n",
    "# features is a dict with keys: tensors from our datagenerator\n",
    "# labels also were in features, but excluded in generator_input_fn by target_key\n",
    "\n",
    "def model_handler(features, labels, mode, params, config):\n",
    "    # Im really like to use make_template instead of variable_scopes and re-usage\n",
    "    extractor = tf.make_template(\n",
    "        'extractor', baseline,\n",
    "        create_scope_now_=True,\n",
    "    )\n",
    "    # wav is a waveform signal with shape (16000, )\n",
    "    wav = features['wav']\n",
    "    # we want to compute spectograms by means of short time fourier transform:\n",
    "    specgram = signal.stft(\n",
    "        wav,\n",
    "        400,  # 16000 [samples per second] * 0.025 [s] -- default stft window frame\n",
    "        160,  # 16000 * 0.010 -- default stride\n",
    "    )\n",
    "    # specgram is a complex tensor, so split it into abs and phase parts:\n",
    "    phase = tf.angle(specgram) / np.pi\n",
    "    # log(1 + abs) is a default transformation for energy units\n",
    "    amp = tf.log1p(tf.abs(specgram))\n",
    "    \n",
    "    x = tf.stack([amp, phase], axis=3) # shape is [bs, time, freq_bins, 2]\n",
    "    x = tf.to_float(x)  # we want to have float32, not float64\n",
    "\n",
    "    logits = extractor(x, params, mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        loss = tf.reduce_mean(\n",
    "            tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits))\n",
    "        # some lr tuner, you could use move interesting functions\n",
    "        def learning_rate_decay_fn(learning_rate, global_step):\n",
    "            return tf.train.exponential_decay(\n",
    "                learning_rate, global_step, decay_steps=10000, decay_rate=0.99)\n",
    "\n",
    "        train_op = tf.contrib.layers.optimize_loss(\n",
    "            loss=loss,\n",
    "            global_step=tf.contrib.framework.get_global_step(),\n",
    "            learning_rate=params.learning_rate,\n",
    "            optimizer=lambda lr: tf.train.MomentumOptimizer(lr, 0.9, use_nesterov=True),\n",
    "            learning_rate_decay_fn=learning_rate_decay_fn,\n",
    "            clip_gradients=params.clip_gradients,\n",
    "            variables=tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES))\n",
    "\n",
    "        specs = dict(\n",
    "            mode=mode,\n",
    "            loss=loss,\n",
    "            train_op=train_op,\n",
    "        )\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        prediction = tf.argmax(logits, axis=-1)\n",
    "        acc, acc_op = tf.metrics.mean_per_class_accuracy(\n",
    "            labels, prediction, params.num_classes)\n",
    "        loss = tf.reduce_mean(\n",
    "            tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits))\n",
    "        specs = dict(\n",
    "            mode=mode,\n",
    "            loss=loss,\n",
    "            eval_metric_ops=dict(\n",
    "                acc=(acc, acc_op),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions = {\n",
    "            'label': tf.argmax(logits, axis=-1),  # for probability just take tf.nn.softmax()\n",
    "            'sample': features['sample'], # it's a hack for simplicity\n",
    "        }\n",
    "        specs = dict(\n",
    "            mode=mode,\n",
    "            predictions=predictions,\n",
    "        )\n",
    "    return tf.estimator.EstimatorSpec(**specs)\n",
    "\n",
    "\n",
    "def create_model(config=None, hparams=None):\n",
    "    return tf.estimator.Estimator(\n",
    "        model_fn=model_handler,\n",
    "        config=config,\n",
    "        params=hparams,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params=dict(\n",
    "    seed=2018,\n",
    "    batch_size=64,\n",
    "    keep_prob=0.5,\n",
    "    learning_rate=1e-3,\n",
    "    clip_gradients=15.0,\n",
    "    use_batch_norm=True,\n",
    "    num_classes=len(POSSIBLE_LABELS),\n",
    ")\n",
    "\n",
    "hparams = tf.contrib.training.HParams(**params)\n",
    "dir_path = os.path.join(OUTDIR, 'eval')\n",
    "\n",
    "if not os.path.exists(dir_path): os.makedirs(dir_path)\n",
    "model_dir = OUTDIR\n",
    "\n",
    "run_config = tf.contrib.learn.RunConfig(model_dir=model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:uid (from tensorflow.contrib.learn.python.learn.estimators.run_config) is experimental and may change or be removed at any time, and without warning.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './model-k', '_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_session_config': None, '_tf_random_seed': None, '_task_type': None, '_environment': 'local', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc35077db10>, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_num_worker_replicas': 0, '_task_id': 0, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_master': '', '_log_step_count_steps': 100}\n",
      "WARNING:tensorflow:uid (from tensorflow.contrib.learn.python.learn.estimators.run_config) is experimental and may change or be removed at any time, and without warning.\n",
      "WARNING:tensorflow:continuous_train_and_eval (from tensorflow.contrib.learn.python.learn.experiment) is experimental and may change or be removed at any time, and without warning.\n",
      "INFO:tensorflow:Training model for 1000 steps\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Tensor conversion requested dtype float32 for Tensor with dtype float64: 'Tensor(\"stft/mul:0\", shape=(64, 98, 400), dtype=float64)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-2d7b0a4f0362>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mrun_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mschedule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"continuous_train_and_eval\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     hparams=hparams)\n\u001b[0m",
      "\u001b[0;32m/home/tommy/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/learn_runner.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(experiment_fn, output_dir, schedule, run_config, hparams)\u001b[0m\n\u001b[1;32m    216\u001b[0m   \u001b[0mschedule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_get_default_schedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_execute_schedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tommy/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/learn_runner.pyc\u001b[0m in \u001b[0;36m_execute_schedule\u001b[0;34m(experiment, schedule)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Allowed values for this experiment are: %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_tasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Schedule references non-callable member %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tommy/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/framework/python/framework/experimental.pyc\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;34m'any time, and without warning.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         decorator_utils.get_qualified_name(func), func.__module__)\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m   new_func.__doc__ = _add_experimental_function_notice_to_docstring(\n\u001b[1;32m     66\u001b[0m       func.__doc__)\n",
      "\u001b[0;32m/home/tommy/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/experiment.pyc\u001b[0m in \u001b[0;36mcontinuous_train_and_eval\u001b[0;34m(self, continuous_eval_predicate_fn)\u001b[0m\n\u001b[1;32m    715\u001b[0m       self._call_train(input_fn=self._train_input_fn,\n\u001b[1;32m    716\u001b[0m                        \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_steps_per_iteration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m                        hooks=self._train_monitors)\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Evaluating model now.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tommy/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/experiment.pyc\u001b[0m in \u001b[0;36m_call_train\u001b[0;34m(self, _sentinel, input_fn, steps, hooks, max_steps)\u001b[0m\n\u001b[1;32m    805\u001b[0m                                    \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m                                    \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m                                    hooks=hooks)\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       return self._estimator.fit(input_fn=input_fn,\n",
      "\u001b[0;32m/home/tommy/anaconda2/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tommy/anaconda2/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.pyc\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m    727\u001b[0m           input_fn, model_fn_lib.ModeKeys.TRAIN)\n\u001b[1;32m    728\u001b[0m       estimator_spec = self._call_model_fn(\n\u001b[0;32m--> 729\u001b[0;31m           features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[1;32m    730\u001b[0m       \u001b[0;31m# Check if the user created a loss summary, and add one if they didn't.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m       \u001b[0;31m# We assume here that the summary is called 'loss'. If it is not, we will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tommy/anaconda2/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.pyc\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'config'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_fn_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_fn_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_fn_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEstimatorSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-d09d6b121e5e>\u001b[0m in \u001b[0;36mmodel_handler\u001b[0;34m(features, labels, mode, params, config)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mwav\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# 16000 [samples per second] * 0.025 [s] -- default stft window frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;36m160\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# 16000 * 0.010 -- default stride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     )\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# specgram is a complex tensor, so split it into abs and phase parts:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tommy/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/signal/python/ops/spectral_ops.pyc\u001b[0m in \u001b[0;36mstft\u001b[0;34m(signals, frame_length, frame_step, fft_length, window_fn, pad_end, name)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;31m# spectral_ops.rfft produces the (fft_length/2 + 1) unique components of the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;31m# FFT of the real windowed signals in framed_signals.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mspectral_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrfft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframed_signals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfft_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tommy/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/spectral_ops.pyc\u001b[0m in \u001b[0;36m_rfft\u001b[0;34m(input_tensor, fft_length, name)\u001b[0m\n\u001b[1;32m    127\u001b[0m     with _ops.name_scope(name, default_name,\n\u001b[1;32m    128\u001b[0m                          [input_tensor, fft_length]) as name:\n\u001b[0;32m--> 129\u001b[0;31m       \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m       \u001b[0minput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_rank_at_least\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfft_rank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mfft_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tommy/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype)\u001b[0m\n\u001b[1;32m    886\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tommy/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tommy/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_TensorTensorConversionFunction\u001b[0;34m(t, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    820\u001b[0m     raise ValueError(\n\u001b[1;32m    821\u001b[0m         \u001b[0;34m\"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m         (dtype.name, t.dtype.name, str(t)))\n\u001b[0m\u001b[1;32m    823\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor conversion requested dtype float32 for Tensor with dtype float64: 'Tensor(\"stft/mul:0\", shape=(64, 98, 400), dtype=float64)'"
     ]
    }
   ],
   "source": [
    "# it's a magic function :)\n",
    "from tensorflow.contrib.learn.python.learn.learn_io.generator_io import generator_input_fn\n",
    "            \n",
    "train_input_fn = generator_input_fn(\n",
    "    x=data_generator(trainset, hparams, 'train'),\n",
    "    target_key='target',  # you could leave target_key in features, so labels in model_handler will be empty\n",
    "    batch_size=hparams.batch_size, shuffle=True, num_epochs=None,\n",
    "    queue_capacity=3 * hparams.batch_size + 10, num_threads=1,\n",
    ")\n",
    "\n",
    "val_input_fn = generator_input_fn(\n",
    "    x=data_generator(valset, hparams, 'val'),\n",
    "    target_key='target',\n",
    "    batch_size=hparams.batch_size, shuffle=True, num_epochs=None,\n",
    "    queue_capacity=3 * hparams.batch_size + 10, num_threads=1,\n",
    ")\n",
    "            \n",
    "\n",
    "def _create_my_experiment(run_config, hparams):\n",
    "    exp = tf.contrib.learn.Experiment(\n",
    "        estimator=create_model(config=run_config, hparams=hparams),\n",
    "        train_input_fn=train_input_fn,\n",
    "        eval_input_fn=val_input_fn,\n",
    "        train_steps=10000, # just randomly selected params\n",
    "        eval_steps=200,  # read source code for steps-epochs ariphmetics\n",
    "        train_steps_per_iteration=1000,\n",
    "    )\n",
    "    return exp\n",
    "\n",
    "tf.contrib.learn.learn_runner.run(\n",
    "    experiment_fn=_create_my_experiment,\n",
    "    run_config=run_config,\n",
    "    schedule=\"continuous_train_and_eval\",\n",
    "    hparams=hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': './model-k', '_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_session_config': None, '_tf_random_seed': None, '_task_type': None, '_environment': 'local', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0d7fdb8350>, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_num_worker_replicas': 0, '_task_id': 0, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_master': '', '_log_step_count_steps': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model-k/model.ckpt-10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "158560it [48:04, 54.98it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# now we want to predict!\n",
    "paths = glob(os.path.join(DATADIR, 'test/audio/*wav'))\n",
    "\n",
    "def test_data_generator(data):\n",
    "    def generator():\n",
    "        for path in data:\n",
    "            _, wav = wavfile.read(path)\n",
    "            wav = wav.astype(np.float32) / np.iinfo(np.int16).max\n",
    "            fname = os.path.basename(path)\n",
    "            yield dict(\n",
    "                sample=np.string_(fname),\n",
    "                wav=wav,\n",
    "            )\n",
    "\n",
    "    return generator\n",
    "\n",
    "test_input_fn = generator_input_fn(\n",
    "    x=test_data_generator(paths),\n",
    "    batch_size=hparams.batch_size, \n",
    "    shuffle=False, \n",
    "    num_epochs=1,\n",
    "    queue_capacity= 10 * hparams.batch_size, \n",
    "    num_threads=1,\n",
    ")\n",
    "\n",
    "model = create_model(config=run_config, hparams=hparams)\n",
    "it = model.predict(input_fn=test_input_fn)\n",
    "\n",
    "\n",
    "# last batch will contain padding, so remove duplicates\n",
    "submission = dict()\n",
    "for t in tqdm(it):\n",
    "    fname, label = t['sample'].decode(), id2name[t['label']]\n",
    "    submission[fname] = label\n",
    "\n",
    "with open(os.path.join(model_dir, 'submission.csv'), 'w') as fout:\n",
    "    fout.write('fname,label\\n')\n",
    "    for fname, label in submission.items():\n",
    "        fout.write('{},{}\\n'.format(fname, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
