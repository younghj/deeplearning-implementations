{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T09:03:29.196238Z",
     "start_time": "2017-11-17T09:03:28.644004Z"
    },
    "_cell_guid": "679e0d3e-646d-4e96-9eb0-b362d8c6e51f",
    "_uuid": "0d05e5ce89af3e25d1c1fb244d021a1cfa1a058c",
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "ERROR (theano.sandbox.cuda): nvcc compiler not found on $PATH. Check your nvcc installation and try again.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from glob import glob\n",
    "# import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import librosa\n",
    "from scipy.io import wavfile\n",
    "import cv2\n",
    "\n",
    "from scipy import signal\n",
    "import random\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.python.keras.models import Model\n",
    "# from tensorflow.python.keras.layers import Add, Input, Conv2D, MaxPooling2D, Activation, BatchNormalization, GlobalAveragePooling2D, GlobalMaxPool2D, concatenate, Dense, Dropout\n",
    "# from tensorflow.python.keras.optimizers import RMSprop\n",
    "# from tensorflow.python.keras.utils import to_categorical\n",
    "\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "# from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.regularizers import l2\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers import Input, Dense, Conv2D, AveragePooling2D, Activation, GlobalAveragePooling2D, Lambda\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.initializers import Initializer\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from PIL import Image\n",
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import imsave, imresize\n",
    "import pydot\n",
    "import graphviz\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from keras.layers import Conv1D, Dense, MaxPooling1D, Flatten, AvgPool1D, Add\n",
    "from keras import backend\n",
    "\n",
    "os.environ[\"THEANO_FLAGS\"] = \"mode=FAST_RUN,device=gpu,floatX=float32\"\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T09:03:29.210749Z",
     "start_time": "2017-11-17T09:03:29.19832Z"
    },
    "_cell_guid": "8ab00801-08b9-44d3-a063-32e82dbf8f58",
    "_uuid": "53c19941676690454dd4b91109976b6c59cb7a40",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "POSSIBLE_LABELS = 'yes no up down left right on off stop go silence unknown'.split()\n",
    "id2name = {i: name for i, name in enumerate(POSSIBLE_LABELS)}\n",
    "name2id = {name: i for i, name in id2name.items()}\n",
    "len(id2name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T09:03:29.325023Z",
     "start_time": "2017-11-17T09:03:29.215137Z"
    },
    "_cell_guid": "8d7ebf53-700b-4c06-b5c2-ccf9ed5f27e0",
    "_uuid": "133424c750b26df37900f9cebcfd2f2fb803cb8b",
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATADIR = './data' # unzipped train and test data\n",
    "OUTDIR = './model-k' # just a random name\n",
    "\n",
    "POSSIBLE_LABELS = 'yes no up down left right on off stop go silence unknown'.split()\n",
    "id2name = {i: name for i, name in enumerate(POSSIBLE_LABELS)}\n",
    "name2id = {name: i for i, name in id2name.items()}\n",
    "\n",
    "\n",
    "def load_data(data_dir):\n",
    "    \"\"\" Return 2 lists of tuples:\n",
    "    [(class_id, user_id, path), ...] for train\n",
    "    [(class_id, user_id, path), ...] for validation\n",
    "    \"\"\"\n",
    "    # Just a simple regexp for paths with three groups:\n",
    "    # prefix, label, user_id\n",
    "    pattern = re.compile(\"(.+\\/)?(\\w+)\\/([^_]+)_.+wav\")\n",
    "    all_files = glob(os.path.join(data_dir, 'train/audio/*/*wav'))\n",
    "\n",
    "    with open(os.path.join(data_dir, 'train/validation_list.txt'), 'r') as fin:\n",
    "        validation_files = fin.readlines()\n",
    "    valset = set()\n",
    "    for entry in validation_files:\n",
    "        r = re.match(pattern, entry)\n",
    "        if r:\n",
    "            valset.add(r.group(3))\n",
    "\n",
    "    possible = set(POSSIBLE_LABELS)\n",
    "    train, val, bg_noise = [], [], []\n",
    "    for entry in all_files:\n",
    "        r = re.match(pattern, entry)\n",
    "        if r:\n",
    "            label, uid = r.group(2), r.group(3)\n",
    "            if label == '_background_noise_':\n",
    "                bg_noise.append(entry)\n",
    "                label = 'silence'\n",
    "            if label not in possible:\n",
    "                label = 'unknown'\n",
    "\n",
    "            label_id = name2id[label]\n",
    "\n",
    "            sample = (label_id, uid, entry)\n",
    "            if uid in valset:\n",
    "                val.append(sample)\n",
    "            else:\n",
    "                train.append(sample)\n",
    "\n",
    "    print('There are {} train, {} val, and {} bg noise samples'.format(len(train), len(val), len(bg_noise)))\n",
    "    return train, val, bg_noise\n",
    "\n",
    "train_df, valid_df, noise_df = load_data(DATADIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T09:03:31.144688Z",
     "start_time": "2017-11-17T09:03:31.105987Z"
    },
    "_cell_guid": "9e32f039-712e-4f1d-9173-ed9804d7771f",
    "_uuid": "36562e906f4fd6739b55582239ab55d947a80766",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_wav_file(origWav):\n",
    "    wav = np.copy(origWav)\n",
    "#     wav = read_wav_file(fname)\n",
    "    \n",
    "    L = 16000  # 1 sec\n",
    "    \n",
    "    if len(wav) > L:\n",
    "        i = np.random.randint(0, len(wav) - L)\n",
    "        wav = wav[i:(i+L)]\n",
    "    elif len(wav) < L:\n",
    "        pad_len = L - len(wav)\n",
    "        silence_part_left  = np.random.uniform(-0.001,0.001,int(pad_len/2.))\n",
    "        silence_part_right = np.random.uniform(-0.001,0.001,int(np.ceil(pad_len/2.)))\n",
    "        wav = np.concatenate([silence_part_left, wav, silence_part_right])\n",
    "        \n",
    "    wav = signal.resample(wav, int(0.5 * wav.shape[0]))\n",
    "    wav = np.expand_dims(wav, axis=1)\n",
    "    wav = np.expand_dims(wav, axis=1)\n",
    "    return wav.astype(np.float32)\n",
    "    specgram = signal.stft(wav, 16000, nperseg = 400, noverlap = 240, nfft = 512, padded = False, boundary = None)\n",
    "    \n",
    "    phase = np.angle(specgram[2]) / np.pi\n",
    "    amp = np.log1p(np.abs(specgram[2]))\n",
    "    \n",
    "#     shape = (96,32)\n",
    "#     phase = imresize(phase, shape, mode='F')\n",
    "#     amp = imresize(amp, shape, mode='F')\n",
    "    \n",
    "    stacked = np.stack([phase, amp], axis = 2)\n",
    "    return stacked\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wav = wav_read(train_df[np.random.randint(len(train_df))][2])\n",
    "p = process_wav_file(wav)\n",
    "a,b = cv2.split(p)\n",
    "shape = (96,32)\n",
    "a = a.astype(np.float32)\n",
    "b = b.astype(np.float32)\n",
    "print b.dtype\n",
    "\n",
    "log_spect = np.log(a)\n",
    "print('spectrogram shape:', log_spect.shape)\n",
    "plt.imshow(log_spect, aspect='auto', origin='lower',)\n",
    "plt.show()\n",
    "\n",
    "a = imresize(a, shape, mode='F')\n",
    "\n",
    "log_spect = np.log(a)\n",
    "print('spectrogram shape:', log_spect.shape)\n",
    "plt.imshow(log_spect, aspect='auto', origin='lower',)\n",
    "plt.show()\n",
    "\n",
    "log_spect = np.log(b)\n",
    "print('spectrogram shape:', log_spect.shape)\n",
    "plt.imshow(log_spect, aspect='auto', origin='lower',)\n",
    "plt.show()\n",
    "\n",
    "b = imresize(b, shape, mode='F')\n",
    "\n",
    "log_spect = np.log(b)\n",
    "print('spectrogram shape:', log_spect.shape)\n",
    "plt.imshow(log_spect, aspect='auto', origin='lower',)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def wav_read(fname):\n",
    "#     wav, _ = librosa.load(fname, sr=None)\n",
    "#     return wav\n",
    "\n",
    "\n",
    "def wav_read(fname):\n",
    "    _, wav = wavfile.read(fname)\n",
    "    wav = wav.astype(np.float32) / np.iinfo(np.int16).max\n",
    "    return wav\n",
    "\n",
    "def normalize_audio(wav):\n",
    "    return wav/max(wav)\n",
    "\n",
    "def time_shift(wav, shift):\n",
    "    start_ = int(shift)\n",
    "    if start_ >= 0:\n",
    "        wav_time_shift = np.r_[wav[start_:], np.random.uniform(-0.001,0.001, start_)]\n",
    "    else:\n",
    "        wav_time_shift = np.r_[np.random.uniform(-0.001,0.001, -start_), wav[:start_]]\n",
    "    return normalize_audio(wav_time_shift)\n",
    "\n",
    "def speed_change(wav, speed_rate):\n",
    "    # rate: lower is faster\n",
    "    wav_speed_tune = cv2.resize(wav, (1, int(len(wav) * speed_rate))).squeeze()\n",
    "    if len(wav_speed_tune) < 16000:\n",
    "        pad_len = 16000 - len(wav_speed_tune)\n",
    "        wav_speed_tune = np.r_[np.random.uniform(-0.001,0.001,int(pad_len/2.)),\n",
    "                               wav_speed_tune,\n",
    "                               np.random.uniform(-0.001,0.001,int(np.ceil(pad_len/2.)))]\n",
    "    else: \n",
    "        cut_len = len(wav_speed_tune) - 16000\n",
    "        wav_speed_tune = wav_speed_tune[int(cut_len/2.):int(cut_len/2.)+16000]\n",
    "    return normalize_audio(wav_speed_tune)\n",
    "\n",
    "def noise_add(wav, percent, ind):\n",
    "    bg = wav_read(noise_df[ind])\n",
    "    bg = normalize_audio(bg)\n",
    "    start_ = np.random.randint(bg.shape[0]-16000)\n",
    "    bg_slice = bg[start_ : start_+16000]\n",
    "    wav_with_bg = wav * percent + bg_slice * (1-percent)\n",
    "    return normalize_audio(wav_with_bg)\n",
    "\n",
    "def get_spectrogram(wav):\n",
    "    v = 600\n",
    "    D = librosa.stft(wav, n_fft=v, hop_length=50,\n",
    "                     win_length=v, window='hamming')\n",
    "    spect, phase = librosa.magphase(D)\n",
    "    spect = scipy.ndimage.zoom(spect,1./7, order=1)\n",
    "    spect = spect.reshape(np.expand_dims(spect, axis=2).shape)\n",
    "    return spect\n",
    "\n",
    "def frange(x, y, jump):\n",
    "    while x < y:\n",
    "        yield x\n",
    "        x += jump\n",
    "        \n",
    "def all_aug(wav, params):\n",
    "    time, speed, noise_percent, noise_ind = params\n",
    "    aug = wav\n",
    "    aug = time_shift(aug, time)\n",
    "    aug = speed_change(wav, speed)\n",
    "    if noise_ind == -1:\n",
    "        aug = noise_add(aug, 1, noise_ind)\n",
    "    else:\n",
    "        aug = noise_add(aug, noise_percent, noise_ind)\n",
    "    return aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def layer(filt, inp, comp):\n",
    "    x = Conv2D(filt, 8, strides=1, padding='same')(inp)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filt, 5, strides=1, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filt, 3, strides=1, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    if not(inp_shape[-1] == filt):\n",
    "        tmp = Conv2D(filt, 1, strides=1, padding='same')(inp)\n",
    "        tmp = BatchNormalization()(tmp)\n",
    "    else:\n",
    "        tmp = BatchNormalization()(x)\n",
    "\n",
    "    x = Add()([x,tmp])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "inp_shape = process_wav_file(wav_read(train_df[0][2])).shape\n",
    "filt = 16\n",
    "\n",
    "l = Input(inp_shape)\n",
    "x = Conv2D(128, 7, strides=4, padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0001))(l)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = layer(filt, x, inp_shape[-1])\n",
    "\n",
    "######\n",
    "filt *= 2\n",
    "\n",
    "x = layer(filt, x, inp_shape[-1])\n",
    "\n",
    "filt *= 2\n",
    "x = layer(filt, x, inp_shape[-1])\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(len(POSSIBLE_LABELS), activation='softmax', kernel_initializer='he_normal', kernel_regularizer=l2(0.0001))(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = Model(l,x)\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "      loss='categorical_crossentropy',\n",
    "      metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T09:03:32.519795Z",
     "start_time": "2017-11-17T09:03:32.483881Z"
    },
    "_cell_guid": "144c6e60-8a83-437d-8b8a-ea065af90923",
    "_uuid": "22e0e6c718171167089fb6df36d3dc43a1029992",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DIV = 100.0\n",
    "\n",
    "def get_variations():\n",
    "    variations = [[0,1,1,-1]]\n",
    "\n",
    "#     time_shift_range = 4000\n",
    "#     for time in xrange(-time_shift_range, time_shift_range+1, 1000):\n",
    "#         for speed in frange(0.4,1.7,0.3):\n",
    "#             for noise_percentage in frange(0.2,1,0.1):\n",
    "#                 for noise_ind in xrange(-1,len(noise_df)):\n",
    "#                     variations.append([time, speed, noise_percentage, noise_ind])\n",
    "    return variations\n",
    "\n",
    "def get_variations_valid():\n",
    "    variations = [[0,1,1,-1]]\n",
    "\n",
    "    time_shift_range = 4000\n",
    "    for time in xrange(-time_shift_range, time_shift_range+1, 1000):\n",
    "        for speed in frange(0.4,1.7,0.3):\n",
    "            for noise_percentage in frange(0.2,1,0.1):\n",
    "                for noise_ind in xrange(-1,len(noise_df)):\n",
    "                    variations.append([time, speed, noise_percentage, noise_ind])\n",
    "    return variations\n",
    "\n",
    "var = get_variations()\n",
    "print len(var)\n",
    "multiplier = np.ceil(len(var)/DIV)\n",
    "\n",
    "def train_generator(train_batch_size):\n",
    "    while True:\n",
    "        variations = get_variations()\n",
    "        len_var = len(variations)\n",
    "        selected_indices = np.random.choice(len_var, int(np.ceil(len_var/DIV)))\n",
    "        \n",
    "        wavs = []\n",
    "        tmp_train_df = np.array(train_df)\n",
    "        np.random.shuffle(tmp_train_df)\n",
    "        tmp_train_df = tmp_train_df.tolist()\n",
    "        \n",
    "        while True:\n",
    "            while len(wavs) < train_batch_size:\n",
    "                label_id, uid, fname = tmp_train_df.pop(0)\n",
    "                wav = wav_read(fname)\n",
    "                for i in selected_indices:\n",
    "                    augmented = all_aug(wav, variations[i])\n",
    "                    arr = [label_id, augmented]\n",
    "                    wavs.append(arr)\n",
    "            \n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            for x in xrange(train_batch_size):\n",
    "                label_id, wav = wavs.pop(0)\n",
    "                x_batch.append(process_wav_file(wav))\n",
    "                y_batch.append(label_id)\n",
    "            \n",
    "            x_batch = np.array(x_batch)\n",
    "            y_batch = to_categorical(y_batch, num_classes=len(POSSIBLE_LABELS))\n",
    "            yield x_batch, y_batch\n",
    "            \n",
    "            if len(tmp_train_df) == 0:\n",
    "                break\n",
    "            \n",
    "def valid_generator(val_batch_size):\n",
    "    while True:\n",
    "\n",
    "        variations = get_variations_valid()\n",
    "        \n",
    "        len_var = len(variations)\n",
    "        selected_indices = np.random.choice(len_var, int(np.ceil(len_var/DIV)))\n",
    "        \n",
    "        wavs = []\n",
    "        tmp_valid_df = np.array(valid_df)\n",
    "        np.random.shuffle(tmp_valid_df)\n",
    "        tmp_valid_df = tmp_valid_df.tolist()\n",
    "        \n",
    "        while True:\n",
    "            while len(wavs) < valid_batch_size:\n",
    "                label_id, uid, fname = tmp_valid_df.pop(0)\n",
    "                wav = wav_read(fname)\n",
    "                for i in selected_indices:\n",
    "                    augmented = all_aug(wav, variations[i])\n",
    "                    arr = [label_id, augmented]\n",
    "                    wavs.append(arr)\n",
    "            \n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            for x in xrange(valid_batch_size):\n",
    "                label_id, wav = wavs.pop(0)\n",
    "                x_batch.append(process_wav_file(wav))\n",
    "                y_batch.append(label_id)\n",
    "            \n",
    "            x_batch = np.array(x_batch)\n",
    "            y_batch = to_categorical(y_batch, num_classes=len(POSSIBLE_LABELS))\n",
    "            yield x_batch, y_batch\n",
    "            \n",
    "            if len(tmp_valid_df) == 0:\n",
    "                break\n",
    "            \n",
    "def test_generator(test_batch_size):\n",
    "    while True:\n",
    "        for start in range(0, len(test_paths), test_batch_size):\n",
    "            x_batch = []\n",
    "            end = min(start + test_batch_size, len(test_paths))\n",
    "            this_paths = test_paths[start:end]\n",
    "            for x in this_paths:\n",
    "                x_batch.append(process_wav_file(x))\n",
    "            x_batch = np.array(x_batch)\n",
    "            yield x_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T09:42:31.48233Z",
     "start_time": "2017-11-17T09:03:33.355603Z"
    },
    "_cell_guid": "5f3d1b09-500f-410e-820a-8eaab24b6ebb",
    "_uuid": "528ec66a0a6caca952273ab916e609625839b19e",
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_loss',\n",
    "                           patience=5,\n",
    "                           verbose=1,\n",
    "                           min_delta=0.01,\n",
    "                           mode='min'),\n",
    "             ReduceLROnPlateau(monitor='val_loss',\n",
    "                               factor=0.1,\n",
    "                               patience=3,\n",
    "                               verbose=1,\n",
    "                               epsilon=0.01,\n",
    "                               mode='min'),\n",
    "             ModelCheckpoint(monitor='val_loss',\n",
    "                             filepath='starter.hdf5',\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=True,\n",
    "                             mode='min',\n",
    "                            verbose=1),\n",
    "             TQDMNotebookCallback()]\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit_generator(generator=train_generator(batch_size),\n",
    "                              steps_per_epoch=int(len(train_df)*multiplier/batch_size),\n",
    "                              epochs=120,\n",
    "                              verbose=1,\n",
    "                              callbacks=callbacks,\n",
    "                              validation_data=valid_generator(batch_size),\n",
    "                              validation_steps=int(len(valid_df)*multiplier/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T10:24:59.198625Z",
     "start_time": "2017-11-17T10:24:59.081762Z"
    },
    "_cell_guid": "0c99ba3b-e8ca-40cb-8d29-2b0e89a385c7",
    "_uuid": "429139ca4f71487c6cfe3e8dfbb6a659eb9bb9c8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('./weights/starter.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T10:28:14.451612Z",
     "start_time": "2017-11-17T10:28:13.307142Z"
    },
    "_cell_guid": "72f27090-c0d1-4d0b-8027-34c915429a79",
    "_uuid": "1007977fccadecdae582ec5d8d52dd3c4c3010aa",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_paths = glob(os.path.join('./data/', 'test/audio/*wav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T10:32:14.882322Z",
     "start_time": "2017-11-17T10:32:14.863617Z"
    },
    "_cell_guid": "c6d9b369-9979-4bcd-8540-4653e6544f84",
    "_uuid": "6a0bb3c22b7b5c43db0ec5673333ab3de8f08724",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-17T10:32:45.947Z"
    },
    "_cell_guid": "1fb8aed4-de12-43c5-84bf-b803e3d640fa",
    "_uuid": "631a38cb0013e5772f6987854145ad76ecf6c430",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(test_generator(64), int(np.ceil(len(test_paths)/64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T11:30:44.236246Z",
     "start_time": "2017-11-17T11:30:44.21858Z"
    },
    "_cell_guid": "b1cdab5c-9816-4690-87d8-de2c97cf0e7d",
    "_uuid": "24eb7e512eace4567494e0a8e356a826f4283c4d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T11:31:11.212517Z",
     "start_time": "2017-11-17T11:31:10.786357Z"
    },
    "_cell_guid": "1da523cf-fdbf-4ab1-9300-0147155aa247",
    "_uuid": "f25d4e626202aa115bd0460f4de8d07f9727c83e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# last batch will contain padding, so remove duplicates\n",
    "submission = dict()\n",
    "for i in range(len(test_paths)):\n",
    "    fname, label = os.path.basename(test_paths[i]), id2name[classes[i]]\n",
    "    submission[fname] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T11:32:05.154527Z",
     "start_time": "2017-11-17T11:32:04.983371Z"
    },
    "_cell_guid": "9a95d147-3f4b-4386-8597-5fa60be43542",
    "_uuid": "bdf63bce43a0525a02ac18ca3f90aeba06ce6e99",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('starter_submission.csv', 'w') as fout:\n",
    "    fout.write('fname,label\\n')\n",
    "    for fname, label in submission.items():\n",
    "        fout.write('{},{}\\n'.format(fname, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8bea6850-15c6-44e7-bdb4-9555ad196f85",
    "_uuid": "555315ef622793711ff5643928dac874c8cb0ed2",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T09:03:33.180074Z",
     "start_time": "2017-11-17T09:03:32.625939Z"
    },
    "_cell_guid": "0e13c01e-5662-4679-9b31-bf9347080ae5",
    "_uuid": "a17b3ea5c15c781260f3473f37dd0d36a932a565",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define model parameters\n",
    "model_depth = 16\n",
    "num_dense_blocks = 3\n",
    "growth_rate = 12\n",
    "number_filters = 16\n",
    "compression = 0.5\n",
    "num_layers_per_block = (model_depth - 4) // num_dense_blocks\n",
    "\n",
    "def dense_block(x,num_layers_per_block,growth_rate):\n",
    "    for i in range(num_layers_per_block//2):\n",
    "        x_ = BatchNormalization()(x)\n",
    "        x_ = Activation('relu')(x_)\n",
    "        x_ = Conv2D(number_filters,(3,3),padding='same',kernel_initializer='he_normal',kernel_regularizer=l2(0.0001))(x_)\n",
    "        x_ = Dropout(0.2)(x_)\n",
    "        x_ = BatchNormalization()(x_)\n",
    "        x_ = Activation('relu')(x_)\n",
    "        x = Concatenate()([x,x_])\n",
    "    return x \n",
    "\n",
    "def transition_layers(x,compression):\n",
    "    updated_num_filters = int(x.get_shape().as_list()[-1] * compression)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(updated_num_filters,(1,1),padding='same',kernel_initializer='he_normal',kernel_regularizer=l2(0.0001))(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = AveragePooling2D()(x)\n",
    "    return x\n",
    "\n",
    "# #Let's define the model\n",
    "# inp = Input(shape = process_wav_file(wav_read(train_df[0][2])).shape)\n",
    "# x = Conv2D(number_filters,(1,1),padding='same',kernel_initializer='he_normal',kernel_regularizer=l2(0.0001))(inp)\n",
    "# for i in range(num_dense_blocks):\n",
    "#     x = dense_block(x,num_layers_per_block,growth_rate)\n",
    "#     if (i != num_dense_blocks-1):\n",
    "#         x = transition_layers(x,compression)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Activation('relu')(x)\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "# x = Dense(32, activation = 'relu')(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "# x = Dense(len(POSSIBLE_LABELS), activation='softmax',kernel_initializer='he_normal',kernel_regularizer=l2(0.0001))(x)\n",
    "\n",
    "# model = Model(inp, x)\n",
    "# # model.compile(Adam(), loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "# model.compile(Adam(), loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "# model.summary()\n",
    "# plot_model(model, to_file='model.png')\n",
    "from keras.layers import Conv1D, Dense, MaxPooling1D, Flatten, AvgPool1D, Add\n",
    "from keras import backend\n",
    "\n",
    "def add(a,b):\n",
    "    shape1 = backend.int_shape(a)\n",
    "    shape2 = backend.int_shape(b)\n",
    "    w = int(round(shape1[1]/shape2[1]))\n",
    "    h = int(round(shape1[2]/shape2[2]))\n",
    "    eq = shape1[3] == shape2[3]\n",
    "    \n",
    "    tmp = a\n",
    "    print w,h,eq\n",
    "    print shape1, shape2\n",
    "    if w>1 or h>1 or not eq:\n",
    "        tmp = Conv2D(filters=shape2[3],kernel_size=(1,1),strides=(w,h),padding='valid',kernel_initializer='he_normal', kernel_regularizer=l2(0.0001))(a)\n",
    "    print backend.int_shape(tmp)\n",
    "    print\n",
    "    return Add()([tmp, b])\n",
    "\n",
    "def layer(num_filt, size, strides, inp):\n",
    "    tmp = BatchNormalization(axis=3)(inp)\n",
    "    tmp = Activation('relu')(tmp)\n",
    "    tmp = Conv2D(num_filt, size, strides=strides, padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0001))(tmp)\n",
    "    return tmp\n",
    "\n",
    "l = Input(process_wav_file(wav_read(train_df[0][2])).shape)\n",
    "\n",
    "x = Conv2D(128, 7, strides=2, padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0001))(l)\n",
    "x = BatchNormalization(axis=3)(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "#first layer\n",
    "num = 32\n",
    "xtmp = Conv2D(num, (1,1), strides=1, \n",
    "              padding='same', \n",
    "              kernel_initializer='he_normal', \n",
    "              kernel_regularizer=l2(0.0001))(x)\n",
    "xtmp = layer(num, 3, 1, xtmp)\n",
    "xtmp = layer(num*4, (1,1), 1, xtmp)\n",
    "\n",
    "x = add(x,xtmp)\n",
    "\n",
    "#other layer\n",
    "xtmp = layer(num, (1,1), 1, x)\n",
    "xtmp = layer(num, 3, 1, xtmp)\n",
    "xtmp = layer(num*4, (1,1), 1, xtmp)\n",
    "x = add(x,xtmp)\n",
    "\n",
    "for i in xrange(4):\n",
    "    num *= 2\n",
    "    xtmp = layer(num, (1,1), 1, x)\n",
    "    xtmp = layer(num, 3, 1, xtmp)\n",
    "    xtmp = layer(num*4, (1,1), 1, xtmp)\n",
    "    x = add(x,xtmp)\n",
    "\n",
    "    #other layer\n",
    "    xtmp = layer(num, (1,1), 1, x)\n",
    "    xtmp = layer(num, 3, 1, xtmp)\n",
    "    xtmp = layer(num*4, (1,1), 1, xtmp)\n",
    "    x = add(x,xtmp)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "xshape = backend.int_shape(x)\n",
    "x = AveragePooling2D(pool_size=(xshape[1],xshape[2]), strides=(1,1))(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(len(POSSIBLE_LABELS), activation='softmax', kernel_initializer='he_normal', kernel_regularizer=l2(0.0001))(x)\n",
    "\n",
    "# x_in = Input(shape = process_wav_file(wav_read(train_df[0][2])).shape)\n",
    "# x = BatchNormalization()(x_in)\n",
    "# for i in range(4):\n",
    "#     x = Conv2D(16*(2 ** i),(3,3),padding='same',kernel_initializer='he_normal',kernel_regularizer=l2(0.0001))(x)\n",
    "# #     x = Conv2D(16*(2 ** i), (3,3))(x)\n",
    "#     x = Activation('elu')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = MaxPooling2D((2,2))(x)\n",
    "# x = Conv2D(128, (1,1))(x)\n",
    "# x_branch_1 = GlobalAveragePooling2D()(x)\n",
    "# x_branch_2 = GlobalMaxPool2D()(x)\n",
    "# x = concatenate([x_branch_1, x_branch_2])\n",
    "# x = Dense(256, activation = 'relu')(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "# x = Dense(len(POSSIBLE_LABELS), activation = 'softmax')(x)\n",
    "# model = Model(inputs = x_in, outputs = x)\n",
    "# model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# model.summary()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "widgets": {
   "state": {
    "649965fbbc9e42129b30e53beb29a77c": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "a63b1c9f5e85472c97ae2af7e875285b": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "b7ba29127a3a4774b0a1ee7f883c267b": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "d35ad1dc88574d2d94e2a39631ca7d30": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
