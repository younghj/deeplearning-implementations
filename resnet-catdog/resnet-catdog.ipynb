{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "# os.environ[\"THEANO_FLAGS\"] = \"mode=FAST_RUN,device=gpu,floatX=float32\"\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Dense, Input, MaxPooling2D, Conv2D, AveragePooling2D, Activation\n",
    "from keras.layers import BatchNormalization, Concatenate, Add, Flatten, Dropout\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "dim = 150\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_gen = datagen.flow_from_directory('dogscats/train',\n",
    "                                       target_size=(dim,dim),\n",
    "                                       batch_size=batch_size,\n",
    "                                       class_mode='binary')\n",
    "\n",
    "valid_gen = test_datagen.flow_from_directory('dogscats/valid',\n",
    "                                       target_size=(dim,dim),\n",
    "                                       batch_size=batch_size,\n",
    "                                       class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resnet_block(conv_val, x, repeat_num):\n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=2)(x)\n",
    "    conv = Conv2D(conv_val, (3,3), strides=1, padding='same', kernel_initializer='he_normal')\n",
    "    for i in xrange(repeat_num):\n",
    "        xtmp = BatchNormalization()(x)\n",
    "        xtmp = Activation('relu')(xtmp)\n",
    "        xtmp = conv(xtmp)\n",
    "    x = Concatenate()([x,xtmp])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = Input((dim, dim, 3))\n",
    "\n",
    "x = Conv2D(64, (7,7), strides=2, padding='same', kernel_initializer='he_normal')(l)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = resnet_block(64, x, 2)\n",
    "x = resnet_block(128, x, 2)\n",
    "x = resnet_block(256, x, 2)\n",
    "x = resnet_block(512, x, 2)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1, activation='sigmoid', kernel_initializer='he_normal', kernel_regularizer=l2(0.0001))(x)\n",
    "\n",
    "early=EarlyStopping(monitor='val_acc', patience=15, verbose=1, mode='auto')\n",
    "filepath=\"weights.best.hdf5\"\n",
    "checkpoint=ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#if training was cut short\n",
    "model = load_model('weights.best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 75, 75, 64)   9472        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 75, 75, 64)   256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 75, 75, 64)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 37, 37, 64)   0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 37, 37, 64)   256         max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 37, 37, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 37, 37, 64)   36928       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 37, 37, 128)  0           max_pooling2d_5[0][0]            \n",
      "                                                                 conv2d_7[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 18, 18, 128)  0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 18, 18, 128)  512         max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 18, 18, 128)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 18, 18, 128)  147584      activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 18, 18, 256)  0           max_pooling2d_6[0][0]            \n",
      "                                                                 conv2d_8[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 8, 8, 256)    0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 8, 8, 256)    1024        max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 8, 8, 256)    0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 8, 8, 256)    590080      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 8, 8, 512)    0           max_pooling2d_7[0][0]            \n",
      "                                                                 conv2d_9[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 3, 3, 512)    0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 3, 3, 512)    2048        max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 3, 3, 512)    0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 3, 3, 512)    2359808     activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 3, 3, 1024)   0           max_pooling2d_8[0][0]            \n",
      "                                                                 conv2d_10[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 3, 3, 1024)   4096        concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 3, 3, 1024)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 1024)         0           activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            1025        global_average_pooling2d_2[0][0] \n",
      "==================================================================================================\n",
      "Total params: 3,153,089\n",
      "Trainable params: 3,148,993\n",
      "Non-trainable params: 4,096\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(l,x)\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(x_train,y_train,\n",
    "          batch_size=2000, epochs=50,\n",
    "          shuffle=True,\n",
    "          validation_data=(x_valid, y_valid), callbacks=[early,checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.6625 - acc: 0.6409Epoch 00001: val_acc improved from -inf to 0.54875, saving model to weights.best.hdf5\n",
      "62/62 [==============================] - 94s 2s/step - loss: 0.6620 - acc: 0.6401 - val_loss: 0.7580 - val_acc: 0.5487\n",
      "Epoch 2/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.5835 - acc: 0.6942Epoch 00002: val_acc did not improve\n",
      "62/62 [==============================] - 88s 1s/step - loss: 0.5850 - acc: 0.6946 - val_loss: 1.3049 - val_acc: 0.5050\n",
      "Epoch 3/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.5412 - acc: 0.7259Epoch 00003: val_acc did not improve\n",
      "62/62 [==============================] - 87s 1s/step - loss: 0.5416 - acc: 0.7263 - val_loss: 1.2252 - val_acc: 0.5050\n",
      "Epoch 4/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.4731 - acc: 0.7731Epoch 00004: val_acc did not improve\n",
      "62/62 [==============================] - 93s 1s/step - loss: 0.4740 - acc: 0.7727 - val_loss: 1.2817 - val_acc: 0.5050\n",
      "Epoch 5/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.4712 - acc: 0.7772Epoch 00005: val_acc improved from 0.54875 to 0.60750, saving model to weights.best.hdf5\n",
      "62/62 [==============================] - 96s 2s/step - loss: 0.4711 - acc: 0.7777 - val_loss: 0.7334 - val_acc: 0.6075\n",
      "Epoch 6/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.4557 - acc: 0.7833Epoch 00006: val_acc did not improve\n",
      "62/62 [==============================] - 98s 2s/step - loss: 0.4580 - acc: 0.7828 - val_loss: 0.8726 - val_acc: 0.5837\n",
      "Epoch 7/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.4563 - acc: 0.7884Epoch 00007: val_acc improved from 0.60750 to 0.71500, saving model to weights.best.hdf5\n",
      "62/62 [==============================] - 99s 2s/step - loss: 0.4546 - acc: 0.7898 - val_loss: 0.6691 - val_acc: 0.7150\n",
      "Epoch 8/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.4253 - acc: 0.8040Epoch 00008: val_acc improved from 0.71500 to 0.71625, saving model to weights.best.hdf5\n",
      "62/62 [==============================] - 98s 2s/step - loss: 0.4261 - acc: 0.8031 - val_loss: 0.5291 - val_acc: 0.7163\n",
      "Epoch 9/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.4104 - acc: 0.8053Epoch 00009: val_acc improved from 0.71625 to 0.76125, saving model to weights.best.hdf5\n",
      "62/62 [==============================] - 97s 2s/step - loss: 0.4067 - acc: 0.8075 - val_loss: 0.4798 - val_acc: 0.7612\n",
      "Epoch 10/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.4079 - acc: 0.8084Epoch 00010: val_acc improved from 0.76125 to 0.79250, saving model to weights.best.hdf5\n",
      "62/62 [==============================] - 98s 2s/step - loss: 0.4070 - acc: 0.8090 - val_loss: 0.4259 - val_acc: 0.7925\n",
      "Epoch 11/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.3788 - acc: 0.8279Epoch 00011: val_acc did not improve\n",
      "62/62 [==============================] - 97s 2s/step - loss: 0.3771 - acc: 0.8291 - val_loss: 0.4556 - val_acc: 0.7750\n",
      "Epoch 12/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.3595 - acc: 0.8361Epoch 00012: val_acc improved from 0.79250 to 0.83625, saving model to weights.best.hdf5\n",
      "62/62 [==============================] - 98s 2s/step - loss: 0.3603 - acc: 0.8352 - val_loss: 0.3869 - val_acc: 0.8363\n",
      "Epoch 13/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.3338 - acc: 0.8468Epoch 00013: val_acc did not improve\n",
      "62/62 [==============================] - 101s 2s/step - loss: 0.3342 - acc: 0.8478 - val_loss: 1.5499 - val_acc: 0.5737\n",
      "Epoch 14/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.3390 - acc: 0.8438Epoch 00014: val_acc did not improve\n",
      "62/62 [==============================] - 99s 2s/step - loss: 0.3423 - acc: 0.8427 - val_loss: 0.4987 - val_acc: 0.7362\n",
      "Epoch 15/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.3410 - acc: 0.8473Epoch 00015: val_acc did not improve\n",
      "62/62 [==============================] - 99s 2s/step - loss: 0.3395 - acc: 0.8483 - val_loss: 0.8192 - val_acc: 0.6400\n",
      "Epoch 16/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.3420 - acc: 0.8458Epoch 00016: val_acc did not improve\n",
      "62/62 [==============================] - 91s 1s/step - loss: 0.3400 - acc: 0.8463 - val_loss: 1.0345 - val_acc: 0.6212\n",
      "Epoch 17/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.3282 - acc: 0.8637Epoch 00017: val_acc did not improve\n",
      "62/62 [==============================] - 87s 1s/step - loss: 0.3302 - acc: 0.8624 - val_loss: 0.4480 - val_acc: 0.7650\n",
      "Epoch 18/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.3300 - acc: 0.8501Epoch 00018: val_acc did not improve\n",
      "62/62 [==============================] - 96s 2s/step - loss: 0.3313 - acc: 0.8485 - val_loss: 0.5057 - val_acc: 0.7538\n",
      "Epoch 19/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.3027 - acc: 0.8596Epoch 00019: val_acc did not improve\n",
      "62/62 [==============================] - 127s 2s/step - loss: 0.3031 - acc: 0.8609 - val_loss: 0.4838 - val_acc: 0.7462\n",
      "Epoch 20/150\n",
      "61/62 [============================>.] - ETA: 2s - loss: 0.3058 - acc: 0.8622Epoch 00020: val_acc did not improve\n",
      "62/62 [==============================] - 143s 2s/step - loss: 0.3039 - acc: 0.8624 - val_loss: 0.5767 - val_acc: 0.7600\n",
      "Epoch 21/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.2980 - acc: 0.8586Epoch 00021: val_acc did not improve\n",
      "62/62 [==============================] - 114s 2s/step - loss: 0.2948 - acc: 0.8609 - val_loss: 0.3813 - val_acc: 0.8263\n",
      "Epoch 22/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.2958 - acc: 0.8755Epoch 00022: val_acc improved from 0.83625 to 0.84250, saving model to weights.best.hdf5\n",
      "62/62 [==============================] - 127s 2s/step - loss: 0.2970 - acc: 0.8750 - val_loss: 0.3665 - val_acc: 0.8425\n",
      "Epoch 23/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.2904 - acc: 0.8730Epoch 00023: val_acc did not improve\n",
      "62/62 [==============================] - 122s 2s/step - loss: 0.2937 - acc: 0.8720 - val_loss: 0.4880 - val_acc: 0.7850\n",
      "Epoch 24/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.2639 - acc: 0.8905Epoch 00024: val_acc did not improve\n",
      "62/62 [==============================] - 128s 2s/step - loss: 0.2633 - acc: 0.8918 - val_loss: 0.5161 - val_acc: 0.7650\n",
      "Epoch 25/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.2562 - acc: 0.8909Epoch 00025: val_acc did not improve\n",
      "62/62 [==============================] - 128s 2s/step - loss: 0.2565 - acc: 0.8906 - val_loss: 0.3453 - val_acc: 0.8425\n",
      "Epoch 26/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.2869 - acc: 0.8730Epoch 00026: val_acc did not improve\n",
      "62/62 [==============================] - 128s 2s/step - loss: 0.2866 - acc: 0.8725 - val_loss: 0.4295 - val_acc: 0.8087\n",
      "Epoch 27/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.2854 - acc: 0.8765Epoch 00027: val_acc improved from 0.84250 to 0.87875, saving model to weights.best.hdf5\n",
      "62/62 [==============================] - 126s 2s/step - loss: 0.2848 - acc: 0.8765 - val_loss: 0.2919 - val_acc: 0.8788\n",
      "Epoch 28/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.2648 - acc: 0.8873Epoch 00028: val_acc did not improve\n",
      "62/62 [==============================] - 125s 2s/step - loss: 0.2633 - acc: 0.8881 - val_loss: 0.3859 - val_acc: 0.8237\n",
      "Epoch 29/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.2390 - acc: 0.9016Epoch 00029: val_acc did not improve\n",
      "62/62 [==============================] - 126s 2s/step - loss: 0.2399 - acc: 0.9002 - val_loss: 0.6738 - val_acc: 0.6775\n",
      "Epoch 30/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.2547 - acc: 0.8965Epoch 00030: val_acc did not improve\n",
      "62/62 [==============================] - 127s 2s/step - loss: 0.2542 - acc: 0.8972 - val_loss: 0.4043 - val_acc: 0.8075\n",
      "Epoch 31/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.2568 - acc: 0.8863Epoch 00031: val_acc did not improve\n",
      "62/62 [==============================] - 121s 2s/step - loss: 0.2598 - acc: 0.8856 - val_loss: 0.3488 - val_acc: 0.8413\n",
      "Epoch 32/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.2603 - acc: 0.8868Epoch 00032: val_acc improved from 0.87875 to 0.89125, saving model to weights.best.hdf5\n",
      "62/62 [==============================] - 123s 2s/step - loss: 0.2619 - acc: 0.8851 - val_loss: 0.2658 - val_acc: 0.8912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.2529 - acc: 0.9011Epoch 00033: val_acc did not improve\n",
      "62/62 [==============================] - 135s 2s/step - loss: 0.2536 - acc: 0.8997 - val_loss: 0.3050 - val_acc: 0.8725\n",
      "Epoch 34/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.2580 - acc: 0.9006Epoch 00034: val_acc did not improve\n",
      "62/62 [==============================] - 127s 2s/step - loss: 0.2558 - acc: 0.9017 - val_loss: 0.2631 - val_acc: 0.8888\n",
      "Epoch 35/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.2382 - acc: 0.9006Epoch 00035: val_acc did not improve\n",
      "62/62 [==============================] - 127s 2s/step - loss: 0.2391 - acc: 0.9002 - val_loss: 0.3530 - val_acc: 0.8363\n",
      "Epoch 36/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.2214 - acc: 0.9062Epoch 00036: val_acc did not improve\n",
      "62/62 [==============================] - 128s 2s/step - loss: 0.2218 - acc: 0.9062 - val_loss: 0.2523 - val_acc: 0.8900\n",
      "Epoch 37/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.2247 - acc: 0.8996Epoch 00037: val_acc did not improve\n",
      "62/62 [==============================] - 120s 2s/step - loss: 0.2245 - acc: 0.8997 - val_loss: 0.2970 - val_acc: 0.8788\n",
      "Epoch 38/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.2229 - acc: 0.9083Epoch 00038: val_acc improved from 0.89125 to 0.89625, saving model to weights.best.hdf5\n",
      "62/62 [==============================] - 128s 2s/step - loss: 0.2245 - acc: 0.9078 - val_loss: 0.2519 - val_acc: 0.8962\n",
      "Epoch 39/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.2408 - acc: 0.8878Epoch 00039: val_acc did not improve\n",
      "62/62 [==============================] - 124s 2s/step - loss: 0.2389 - acc: 0.8891 - val_loss: 0.2770 - val_acc: 0.8700\n",
      "Epoch 40/150\n",
      "61/62 [============================>.] - ETA: 2s - loss: 0.2364 - acc: 0.8970Epoch 00040: val_acc did not improve\n",
      "62/62 [==============================] - 155s 3s/step - loss: 0.2339 - acc: 0.8987 - val_loss: 0.2848 - val_acc: 0.8738\n",
      "Epoch 41/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.2412 - acc: 0.8945Epoch 00041: val_acc improved from 0.89625 to 0.90500, saving model to weights.best.hdf5\n",
      "62/62 [==============================] - 122s 2s/step - loss: 0.2400 - acc: 0.8947 - val_loss: 0.2374 - val_acc: 0.9050\n",
      "Epoch 42/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.2131 - acc: 0.9114Epoch 00042: val_acc did not improve\n",
      "62/62 [==============================] - 98s 2s/step - loss: 0.2109 - acc: 0.9128 - val_loss: 0.2363 - val_acc: 0.9012\n",
      "Epoch 43/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.1985 - acc: 0.9206Epoch 00043: val_acc did not improve\n",
      "62/62 [==============================] - 100s 2s/step - loss: 0.1967 - acc: 0.9214 - val_loss: 0.3850 - val_acc: 0.8200\n",
      "Epoch 44/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.2123 - acc: 0.9052Epoch 00044: val_acc did not improve\n",
      "62/62 [==============================] - 98s 2s/step - loss: 0.2118 - acc: 0.9052 - val_loss: 0.2623 - val_acc: 0.8825\n",
      "Epoch 45/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.2076 - acc: 0.9160Epoch 00045: val_acc did not improve\n",
      "62/62 [==============================] - 99s 2s/step - loss: 0.2092 - acc: 0.9163 - val_loss: 0.3074 - val_acc: 0.8662\n",
      "Epoch 46/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.2085 - acc: 0.9221Epoch 00046: val_acc did not improve\n",
      "62/62 [==============================] - 99s 2s/step - loss: 0.2080 - acc: 0.9214 - val_loss: 0.3781 - val_acc: 0.8087\n",
      "Epoch 47/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.2109 - acc: 0.9068Epoch 00047: val_acc did not improve\n",
      "62/62 [==============================] - 99s 2s/step - loss: 0.2103 - acc: 0.9068 - val_loss: 0.2396 - val_acc: 0.8938\n",
      "Epoch 48/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.2105 - acc: 0.9083Epoch 00048: val_acc did not improve\n",
      "62/62 [==============================] - 100s 2s/step - loss: 0.2105 - acc: 0.9078 - val_loss: 0.3093 - val_acc: 0.8688\n",
      "Epoch 49/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.2032 - acc: 0.9144Epoch 00049: val_acc did not improve\n",
      "62/62 [==============================] - 102s 2s/step - loss: 0.2019 - acc: 0.9148 - val_loss: 0.3659 - val_acc: 0.8638\n",
      "Epoch 50/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.1893 - acc: 0.9180Epoch 00050: val_acc did not improve\n",
      "62/62 [==============================] - 101s 2s/step - loss: 0.1899 - acc: 0.9183 - val_loss: 0.2613 - val_acc: 0.8875\n",
      "Epoch 51/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.2173 - acc: 0.9134Epoch 00051: val_acc did not improve\n",
      "62/62 [==============================] - 126s 2s/step - loss: 0.2182 - acc: 0.9128 - val_loss: 0.3621 - val_acc: 0.8313\n",
      "Epoch 52/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.1984 - acc: 0.9180Epoch 00052: val_acc did not improve\n",
      "62/62 [==============================] - 126s 2s/step - loss: 0.1971 - acc: 0.9189 - val_loss: 0.2537 - val_acc: 0.8900\n",
      "Epoch 53/150\n",
      "61/62 [============================>.] - ETA: 2s - loss: 0.2350 - acc: 0.8940Epoch 00053: val_acc did not improve\n",
      "62/62 [==============================] - 143s 2s/step - loss: 0.2337 - acc: 0.8947 - val_loss: 0.2783 - val_acc: 0.8875\n",
      "Epoch 54/150\n",
      "61/62 [============================>.] - ETA: 2s - loss: 0.2097 - acc: 0.9124Epoch 00054: val_acc did not improve\n",
      "62/62 [==============================] - 142s 2s/step - loss: 0.2094 - acc: 0.9123 - val_loss: 0.2778 - val_acc: 0.8750\n",
      "Epoch 55/150\n",
      "61/62 [============================>.] - ETA: 2s - loss: 0.1858 - acc: 0.9278Epoch 00055: val_acc did not improve\n",
      "62/62 [==============================] - 148s 2s/step - loss: 0.1849 - acc: 0.9284 - val_loss: 0.2386 - val_acc: 0.9050\n",
      "Epoch 56/150\n",
      "61/62 [============================>.] - ETA: 1s - loss: 0.2159 - acc: 0.9170Epoch 00056: val_acc did not improve\n",
      "62/62 [==============================] - 108s 2s/step - loss: 0.2138 - acc: 0.9183 - val_loss: 0.3324 - val_acc: 0.8550\n",
      "Epoch 00056: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f280cc58ad0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "        train_gen,\n",
    "        steps_per_epoch=2000 // batch_size,\n",
    "        epochs=150,\n",
    "        validation_data=valid_gen,\n",
    "        validation_steps=800 // batch_size,\n",
    "        callbacks=[early,checkpoint],\n",
    "        shuffle=True,\n",
    "        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = model.evaluate_generator(valid_gen, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.34 Accuracy: 84.64%\n"
     ]
    }
   ],
   "source": [
    "print('Loss: %.2f Accuracy: %.2f%%' % (res[0], res[1]*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
